{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation: ARIMA\n",
    "\n",
    "Simple ARIMA (p,d,q)(P,D,Q,m) model.  Order and seasonal order chosen using `pmdarima.auto_arima`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#stats models imports for tsa\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "#auto_arima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "\n",
    "#forecast error metrics\n",
    "from forecast_tools.metrics import (mean_absolute_scaled_error, \n",
    "                                    root_mean_squared_error,\n",
    "                                    symmetric_mean_absolute_percentage_error)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "The constants `TOP_LEVEL`, `STAGE`, `REGION`,`TRUST` and `METHOD` are used to control data selection and the directory for outputting results.  \n",
    "\n",
    "> Output file is `f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv'.csv`.  where metric will be smape, rmse, mase, coverage_80 and coverage_95. Note: `REGION`: is also used to select the correct data from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_LEVEL = '../../../results/model_selection'\n",
    "STAGE = 'stage1'\n",
    "REGION = 'Trust'\n",
    "METHOD = 'arima'\n",
    "\n",
    "FILE_NAME = 'Daily_Responses_5_Years_2019_full.csv'\n",
    "\n",
    "#split training and test data.\n",
    "TEST_SPLIT_DATE = '2019-01-01'\n",
    "\n",
    "#second subdivide: train and val\n",
    "VAL_SPLIT_DATE = '2017-07-01'\n",
    "\n",
    "#discard data after 2020 due to coronavirus\n",
    "#this is the subject of a seperate study.\n",
    "DISCARD_DATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in path\n",
    "path = f'../../../data/{FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_daily_data(path, index_col, by_col, \n",
    "                           values, dayfirst=False):\n",
    "    '''\n",
    "    Daily data is stored in long format.  Read in \n",
    "    and pivot to wide format so that there is a single \n",
    "    colmumn for each regions time series.\n",
    "    '''\n",
    "    df = pd.read_csv(path, index_col=index_col, parse_dates=True, \n",
    "                     dayfirst=dayfirst)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.index.rename(str(df.index.name).lower(), inplace=True)\n",
    "    \n",
    "    clean_table = pd.pivot_table(df, values=values.lower(), \n",
    "                                 index=[index_col.lower()],\n",
    "                                 columns=[by_col.lower()], aggfunc=np.sum)\n",
    "    \n",
    "    clean_table.index.freq = 'D'\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  \n",
       "actual_dt                      \n",
       "2013-12-30  2042.0      255.0  \n",
       "2013-12-31  1996.0      260.0  \n",
       "2014-01-01  2570.0      351.0  \n",
       "2014-01-02  2013.0      258.0  \n",
       "2014-01-03  2056.0      269.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pre_process_daily_data(path, 'Actual_dt', 'ORA', 'Actual_Value', \n",
    "                               dayfirst=False)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ts_train_test_split(clean, split_date=TEST_SPLIT_DATE)\n",
    "\n",
    "#exclude data after 2020 due to coronavirus.\n",
    "test, discard = ts_train_test_split(test, split_date=DISCARD_DATE)\n",
    "\n",
    "#train split into train and validation\n",
    "train, val = ts_train_test_split(train, split_date=VAL_SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 9)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 9)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Auto ARIMA function to select model using the Hyndman-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only looking at Trust level.\n",
    "#auto_results = auto_arima(train[REGION], seasonal=True, m=7, n_job=-1, \n",
    "#                          suppress_warnings=True) \n",
    "#auto_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation\n",
    "\n",
    "`time_series_cv` implements rolling forecast origin cross validation for time series.  \n",
    "It does not calculate forecast error, but instead returns the predictions, pred intervals and actuals in an array that can be passed to any forecast error function. (this is for efficiency and allows additional metrics to be calculated if needed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA Wrapper Class\n",
    "`ARIMAWrapper` is a facade for `ARIMA`.  Provides additional flexibility for ARIMA objects to fit in with common TSCV across methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARIMAWrapper:\n",
    "    '''\n",
    "    Facade for statsmodels.statespace\n",
    "    '''\n",
    "    def __init__(self, order, seasonal_order, training_index, holidays=None):\n",
    "        self._order = order\n",
    "        self._seasonal_order = seasonal_order\n",
    "        self._training_index = training_index\n",
    "        self._holidays = holidays\n",
    "\n",
    "    def _get_resids(self):\n",
    "        return self._fitted.resid\n",
    "\n",
    "    def _get_preds(self):\n",
    "        return self._fitted.fittedvalues\n",
    "    \n",
    "    def _encode_holidays(self, holidays, idx):\n",
    "        dummy = idx.isin(holidays).astype(int)\n",
    "        dummy = pd.DataFrame(dummy)\n",
    "        dummy.columns = ['holiday']\n",
    "        dummy.index = idx\n",
    "        return dummy\n",
    "\n",
    "    def fit(self, y_train):\n",
    "        \n",
    "        #extend training index\n",
    "        if len(y_train) > len(self._training_index):\n",
    "\n",
    "            self._training_index = pd.date_range(start=self._training_index[0], \n",
    "                                                 periods=len(y_train),\n",
    "                                                 freq=self._training_index.freq)\n",
    "            \n",
    "        holiday_train = None\n",
    "        if not self._holidays is None:\n",
    "            holiday_train = self._encode_holidays(self._holidays, \n",
    "                                                  self._training_index)\n",
    "    \n",
    "        \n",
    "        self._model = ARIMA(endog=y_train,\n",
    "                            exog=holiday_train,\n",
    "                            order=self._order, \n",
    "                            seasonal_order=self._seasonal_order)#,\n",
    "                            #enforce_stationarity=False)\n",
    "        \n",
    "        self._fitted = self._model.fit()\n",
    "        self._t = len(train)\n",
    "        \n",
    "    \n",
    "    def predict(self, horizon, return_conf_int=False, alpha=0.2):\n",
    "        '''\n",
    "        forecast h steps ahead.\n",
    "        \n",
    "        Params:\n",
    "        ------\n",
    "        h: int\n",
    "            h-step forecast\n",
    "        \n",
    "        return_conf_int: bool, optional (default=False)\n",
    "            return 1 - alpha PI\n",
    "        \n",
    "        alpha: float, optional (default=0.2)\n",
    "            return 1 - alpha PI\n",
    "                       \n",
    "        Returns:\n",
    "        -------\n",
    "        np.array\n",
    "            If return_conf_int = False returns preds only\n",
    "            \n",
    "        np.array, np.array\n",
    "            If return_conf_int = True returns tuple of preds, pred_ints\n",
    "        '''\n",
    "        \n",
    "        #+1 to date range then trim off the first value\n",
    "\n",
    "        f_idx = pd.date_range(start=self._training_index[-1], \n",
    "                              periods=horizon+1,\n",
    "                              freq=self._training_index.freq)[1:]\n",
    "        \n",
    "        #encode holidays if included.\n",
    "        exog_holiday = None\n",
    "        if not self._holidays is None:\n",
    "            exog_holiday = self._encode_holidays(self._holidays, f_idx)\n",
    "        \n",
    "    \n",
    "        forecast = self._fitted.get_forecast(horizon, exog=exog_holiday)\n",
    "        mean_forecast = forecast.summary_frame()['mean'].to_numpy()\n",
    "        \n",
    "        if return_conf_int:\n",
    "            df = forecast.summary_frame(alpha=alpha)\n",
    "            pi = df[['mean_ci_lower', 'mean_ci_upper']].to_numpy()\n",
    "            return mean_forecast, pi\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            return mean_forecast\n",
    "\n",
    "    fittedvalues = property(_get_preds)\n",
    "    resid = property(_get_resids)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(model, train, val, horizons, alpha=0.2, step=1):\n",
    "    '''\n",
    "    Time series cross validation across multiple horizons for a single model.\n",
    "\n",
    "    Incrementally adds additional training data to the model and tests\n",
    "    across a provided list of forecast horizons. Note that function tests a\n",
    "    model only against complete validation sets.  E.g. if horizon = 15 and \n",
    "    len(val) = 12 then no testing is done.  In the case of multiple horizons\n",
    "    e.g. [7, 14, 28] then the function will use the maximum forecast horizon\n",
    "    to calculate the number of iterations i.e if len(val) = 365 and step = 1\n",
    "    then no. iterations = len(val) - max(horizon) = 365 - 28 = 337.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    model - forecasting model\n",
    "\n",
    "    error_func - function to measure forecast error\n",
    "\n",
    "    train - np.array - vector of training data\n",
    "\n",
    "    val - np.array - vector of validation data\n",
    "\n",
    "    horizon - list of ints, forecast horizon e.g. [7, 14, 28] days\n",
    "\n",
    "    step -- step taken in cross validation \n",
    "            e.g. 1 in next cross validation training data includes next point \n",
    "            from the validation set.\n",
    "            e.g. 7 in the next cross validation training data includes next 7 points\n",
    "            (default=1)\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    np.array - vector of forecast errors from the CVs.\n",
    "    '''\n",
    "    cv_preds = [] #mean forecast\n",
    "    cv_actuals = [] # actuals \n",
    "    cv_pis = [] #prediction intervals\n",
    "    split = 0\n",
    "\n",
    "    print('split => ', end=\"\")\n",
    "    for i in range(0, len(val) - max(horizons) + 1, step):\n",
    "        split += 1\n",
    "        print(f'{split}, ', end=\"\")\n",
    "                \n",
    "        train_cv = np.concatenate([train, val[:i]], axis=0)\n",
    "        model.fit(train_cv)\n",
    "        \n",
    "        #predict the maximum horizon \n",
    "        preds, pis = model.predict(horizon=len(val[i:i+max(horizons)]), \n",
    "                                   return_conf_int=True,\n",
    "                                   alpha=alpha)\n",
    "        \n",
    "        cv_h_preds = []\n",
    "        cv_test = []\n",
    "        cv_h_pis = []\n",
    "        \n",
    "        for h in horizons:\n",
    "            #store the h-step prediction\n",
    "            cv_h_preds.append(preds[:h])\n",
    "            #store the h-step actual value\n",
    "            cv_test.append(val.iloc[i:i+h])    \n",
    "            cv_h_pis.append(pis[:h])\n",
    "                     \n",
    "        cv_preds.append(cv_h_preds)\n",
    "        cv_actuals.append(cv_test)\n",
    "        cv_pis.append(cv_h_pis)\n",
    "        \n",
    "    print('done.\\n')        \n",
    "    return cv_preds, cv_actuals, cv_pis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for calculating CV scores for point predictions and coverage.\n",
    "\n",
    "These functions have been written to work with the output of `time_series_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast error in the current split\n",
    "    \n",
    "    Params:\n",
    "    -----\n",
    "    cv_preds, np.array\n",
    "        Split predictions\n",
    "        \n",
    "    \n",
    "    cv_test: np.array\n",
    "        acutal ground truth observations\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        np.ndarray\n",
    "            cross validation errors for split\n",
    "    '''\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = error_func(cv_test[split], cv_preds[split])\n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast errors by forecast horizon\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    cv_preds: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    cv_test: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        \n",
    "    '''\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error(cv_preds[h], cv_test[h], error_func)\n",
    "        horizon_errors.append(split_errors)\n",
    "\n",
    "    return np.array(horizon_errors)\n",
    "\n",
    "def split_coverage(cv_test, cv_intervals):\n",
    "    n_splits = len(cv_test)\n",
    "    cv_errors = []\n",
    "        \n",
    "    for split in range(n_splits):\n",
    "        val = np.asarray(cv_test[split])\n",
    "        lower = cv_intervals[split].T[0]\n",
    "        upper = cv_intervals[split].T[1]\n",
    "        \n",
    "        coverage = len(np.where((val > lower) & (val < upper))[0])\n",
    "        coverage = coverage / len(val)\n",
    "        \n",
    "        cv_errors.append(coverage)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "    \n",
    "    \n",
    "def prediction_int_coverage_cv(cv_test, cv_intervals):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_intervals = np.array(cv_intervals)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_coverage = []\n",
    "    for h in range(n_horizons):\n",
    "        split_coverages = split_coverage(cv_test[h], cv_intervals[h])\n",
    "        horizon_coverage.append(split_coverages)\n",
    "\n",
    "    return np.array(horizon_coverage)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error_scaled(cv_preds, cv_test, y_train):\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = mean_absolute_scaled_error(cv_test[split], cv_preds[split], \n",
    "                                                y_train, period=7)\n",
    "        \n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv_scaled(cv_preds, cv_test, y_train):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error_scaled(cv_preds[h], cv_test[h], y_train)\n",
    "        horizon_errors.append(split_errors)\n",
    "        \n",
    "    return np.array(horizon_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Cross Validation\n",
    "\n",
    "This is run twices once each for 80 and 95% prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ARIMAWrapper(order=(1,1,3), seasonal_order=(1,0,1,7), \n",
    "                     training_index=train.index )\n",
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.2, step=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds, cv_test, cv_intervals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.035132</td>\n",
       "      <td>3.392277</td>\n",
       "      <td>3.583495</td>\n",
       "      <td>3.729142</td>\n",
       "      <td>3.865357</td>\n",
       "      <td>3.978708</td>\n",
       "      <td>4.065642</td>\n",
       "      <td>4.137531</td>\n",
       "      <td>4.220929</td>\n",
       "      <td>4.273174</td>\n",
       "      <td>4.321929</td>\n",
       "      <td>4.395273</td>\n",
       "      <td>4.940061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.262805</td>\n",
       "      <td>1.281414</td>\n",
       "      <td>1.188705</td>\n",
       "      <td>1.138401</td>\n",
       "      <td>1.183108</td>\n",
       "      <td>1.191705</td>\n",
       "      <td>1.171287</td>\n",
       "      <td>1.118916</td>\n",
       "      <td>1.088968</td>\n",
       "      <td>1.022889</td>\n",
       "      <td>0.980988</td>\n",
       "      <td>1.002567</td>\n",
       "      <td>1.450380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.577649</td>\n",
       "      <td>1.683922</td>\n",
       "      <td>2.208552</td>\n",
       "      <td>2.545710</td>\n",
       "      <td>2.569328</td>\n",
       "      <td>2.623963</td>\n",
       "      <td>2.547736</td>\n",
       "      <td>2.667818</td>\n",
       "      <td>2.850693</td>\n",
       "      <td>3.028543</td>\n",
       "      <td>2.973107</td>\n",
       "      <td>3.002794</td>\n",
       "      <td>3.675961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.093875</td>\n",
       "      <td>2.645470</td>\n",
       "      <td>2.782894</td>\n",
       "      <td>2.800936</td>\n",
       "      <td>2.946880</td>\n",
       "      <td>3.126364</td>\n",
       "      <td>3.286685</td>\n",
       "      <td>3.286695</td>\n",
       "      <td>3.450556</td>\n",
       "      <td>3.630111</td>\n",
       "      <td>3.728494</td>\n",
       "      <td>3.681126</td>\n",
       "      <td>3.926416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.826170</td>\n",
       "      <td>2.989510</td>\n",
       "      <td>3.160257</td>\n",
       "      <td>3.425163</td>\n",
       "      <td>3.399747</td>\n",
       "      <td>3.542341</td>\n",
       "      <td>3.582434</td>\n",
       "      <td>3.905213</td>\n",
       "      <td>3.867323</td>\n",
       "      <td>3.977032</td>\n",
       "      <td>4.007547</td>\n",
       "      <td>4.075594</td>\n",
       "      <td>4.939773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.588407</td>\n",
       "      <td>3.731665</td>\n",
       "      <td>3.963487</td>\n",
       "      <td>4.159276</td>\n",
       "      <td>4.617119</td>\n",
       "      <td>4.528372</td>\n",
       "      <td>4.461585</td>\n",
       "      <td>4.398957</td>\n",
       "      <td>4.510204</td>\n",
       "      <td>4.868421</td>\n",
       "      <td>4.986627</td>\n",
       "      <td>5.261835</td>\n",
       "      <td>5.308781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.726198</td>\n",
       "      <td>7.328785</td>\n",
       "      <td>6.641379</td>\n",
       "      <td>6.284334</td>\n",
       "      <td>6.660583</td>\n",
       "      <td>6.948891</td>\n",
       "      <td>6.637317</td>\n",
       "      <td>6.980925</td>\n",
       "      <td>6.634661</td>\n",
       "      <td>6.213411</td>\n",
       "      <td>5.920411</td>\n",
       "      <td>6.277706</td>\n",
       "      <td>10.961270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    3.035132   3.392277   3.583495   3.729142   3.865357   3.978708   \n",
       "std     1.262805   1.281414   1.188705   1.138401   1.183108   1.191705   \n",
       "min     1.577649   1.683922   2.208552   2.545710   2.569328   2.623963   \n",
       "25%     2.093875   2.645470   2.782894   2.800936   2.946880   3.126364   \n",
       "50%     2.826170   2.989510   3.160257   3.425163   3.399747   3.542341   \n",
       "75%     3.588407   3.731665   3.963487   4.159276   4.617119   4.528372   \n",
       "max     6.726198   7.328785   6.641379   6.284334   6.660583   6.948891   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    4.065642   4.137531   4.220929   4.273174   4.321929   4.395273   \n",
       "std     1.171287   1.118916   1.088968   1.022889   0.980988   1.002567   \n",
       "min     2.547736   2.667818   2.850693   3.028543   2.973107   3.002794   \n",
       "25%     3.286685   3.286695   3.450556   3.630111   3.728494   3.681126   \n",
       "50%     3.582434   3.905213   3.867323   3.977032   4.007547   4.075594   \n",
       "75%     4.461585   4.398957   4.510204   4.868421   4.986627   5.261835   \n",
       "max     6.637317   6.980925   6.634661   6.213411   5.920411   6.277706   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    4.940061  \n",
       "std     1.450380  \n",
       "min     3.675961  \n",
       "25%     3.926416  \n",
       "50%     4.939773  \n",
       "75%     5.308781  \n",
       "max    10.961270  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions smape\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, \n",
    "                               symmetric_mean_absolute_percentage_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-arima_smape.csv\n"
     ]
    }
   ],
   "source": [
    "#output sMAPE results to file\n",
    "metric = 'smape'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.328904</td>\n",
       "      <td>92.775766</td>\n",
       "      <td>99.883690</td>\n",
       "      <td>104.923147</td>\n",
       "      <td>109.545176</td>\n",
       "      <td>113.361307</td>\n",
       "      <td>116.520853</td>\n",
       "      <td>119.278348</td>\n",
       "      <td>122.305484</td>\n",
       "      <td>124.653390</td>\n",
       "      <td>126.789933</td>\n",
       "      <td>129.456951</td>\n",
       "      <td>142.349451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>38.906192</td>\n",
       "      <td>41.974036</td>\n",
       "      <td>41.129839</td>\n",
       "      <td>40.299836</td>\n",
       "      <td>40.687146</td>\n",
       "      <td>40.414737</td>\n",
       "      <td>39.749977</td>\n",
       "      <td>38.516219</td>\n",
       "      <td>37.260434</td>\n",
       "      <td>35.419301</td>\n",
       "      <td>34.033853</td>\n",
       "      <td>33.596446</td>\n",
       "      <td>32.849969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>37.749829</td>\n",
       "      <td>43.520465</td>\n",
       "      <td>60.417265</td>\n",
       "      <td>69.166256</td>\n",
       "      <td>73.204175</td>\n",
       "      <td>74.015983</td>\n",
       "      <td>72.642331</td>\n",
       "      <td>74.519751</td>\n",
       "      <td>78.691607</td>\n",
       "      <td>81.503218</td>\n",
       "      <td>80.722929</td>\n",
       "      <td>82.153078</td>\n",
       "      <td>114.233418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>57.800416</td>\n",
       "      <td>71.033397</td>\n",
       "      <td>75.189682</td>\n",
       "      <td>81.028438</td>\n",
       "      <td>80.303346</td>\n",
       "      <td>85.010126</td>\n",
       "      <td>85.740147</td>\n",
       "      <td>88.909605</td>\n",
       "      <td>93.529514</td>\n",
       "      <td>99.041547</td>\n",
       "      <td>101.323494</td>\n",
       "      <td>103.663933</td>\n",
       "      <td>120.374767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.097905</td>\n",
       "      <td>81.690905</td>\n",
       "      <td>88.022121</td>\n",
       "      <td>89.202388</td>\n",
       "      <td>90.776345</td>\n",
       "      <td>93.853076</td>\n",
       "      <td>97.465912</td>\n",
       "      <td>103.750943</td>\n",
       "      <td>109.981670</td>\n",
       "      <td>116.709021</td>\n",
       "      <td>122.733264</td>\n",
       "      <td>127.627702</td>\n",
       "      <td>139.158825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89.501130</td>\n",
       "      <td>92.777513</td>\n",
       "      <td>102.352072</td>\n",
       "      <td>106.782087</td>\n",
       "      <td>118.676985</td>\n",
       "      <td>143.226686</td>\n",
       "      <td>149.844926</td>\n",
       "      <td>149.473017</td>\n",
       "      <td>147.418253</td>\n",
       "      <td>149.612130</td>\n",
       "      <td>156.014156</td>\n",
       "      <td>158.305824</td>\n",
       "      <td>151.045195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>225.863437</td>\n",
       "      <td>241.936372</td>\n",
       "      <td>212.734803</td>\n",
       "      <td>209.510880</td>\n",
       "      <td>209.277748</td>\n",
       "      <td>209.924755</td>\n",
       "      <td>201.874777</td>\n",
       "      <td>206.106965</td>\n",
       "      <td>198.716598</td>\n",
       "      <td>189.972576</td>\n",
       "      <td>183.067628</td>\n",
       "      <td>186.420896</td>\n",
       "      <td>280.863006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              7           14          21          28          35          42   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    81.328904   92.775766   99.883690  104.923147  109.545176  113.361307   \n",
       "std     38.906192   41.974036   41.129839   40.299836   40.687146   40.414737   \n",
       "min     37.749829   43.520465   60.417265   69.166256   73.204175   74.015983   \n",
       "25%     57.800416   71.033397   75.189682   81.028438   80.303346   85.010126   \n",
       "50%     74.097905   81.690905   88.022121   89.202388   90.776345   93.853076   \n",
       "75%     89.501130   92.777513  102.352072  106.782087  118.676985  143.226686   \n",
       "max    225.863437  241.936372  212.734803  209.510880  209.277748  209.924755   \n",
       "\n",
       "              49          56          63          70          77          84   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean   116.520853  119.278348  122.305484  124.653390  126.789933  129.456951   \n",
       "std     39.749977   38.516219   37.260434   35.419301   34.033853   33.596446   \n",
       "min     72.642331   74.519751   78.691607   81.503218   80.722929   82.153078   \n",
       "25%     85.740147   88.909605   93.529514   99.041547  101.323494  103.663933   \n",
       "50%     97.465912  103.750943  109.981670  116.709021  122.733264  127.627702   \n",
       "75%    149.844926  149.473017  147.418253  149.612130  156.014156  158.305824   \n",
       "max    201.874777  206.106965  198.716598  189.972576  183.067628  186.420896   \n",
       "\n",
       "              365  \n",
       "count   27.000000  \n",
       "mean   142.349451  \n",
       "std     32.849969  \n",
       "min    114.233418  \n",
       "25%    120.374767  \n",
       "50%    139.158825  \n",
       "75%    151.045195  \n",
       "max    280.863006  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions rmse\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, root_mean_squared_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-arima_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'rmse'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.822299</td>\n",
       "      <td>0.921157</td>\n",
       "      <td>0.974330</td>\n",
       "      <td>1.014737</td>\n",
       "      <td>1.052366</td>\n",
       "      <td>1.083733</td>\n",
       "      <td>1.107944</td>\n",
       "      <td>1.127696</td>\n",
       "      <td>1.150705</td>\n",
       "      <td>1.165272</td>\n",
       "      <td>1.179067</td>\n",
       "      <td>1.199488</td>\n",
       "      <td>1.341217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.387519</td>\n",
       "      <td>0.398337</td>\n",
       "      <td>0.372758</td>\n",
       "      <td>0.358631</td>\n",
       "      <td>0.367517</td>\n",
       "      <td>0.366709</td>\n",
       "      <td>0.358215</td>\n",
       "      <td>0.341111</td>\n",
       "      <td>0.329969</td>\n",
       "      <td>0.308926</td>\n",
       "      <td>0.293755</td>\n",
       "      <td>0.295900</td>\n",
       "      <td>0.414752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.412711</td>\n",
       "      <td>0.444991</td>\n",
       "      <td>0.593176</td>\n",
       "      <td>0.646963</td>\n",
       "      <td>0.663596</td>\n",
       "      <td>0.675018</td>\n",
       "      <td>0.653409</td>\n",
       "      <td>0.683681</td>\n",
       "      <td>0.734620</td>\n",
       "      <td>0.783252</td>\n",
       "      <td>0.768834</td>\n",
       "      <td>0.781345</td>\n",
       "      <td>0.999604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.549874</td>\n",
       "      <td>0.698068</td>\n",
       "      <td>0.712893</td>\n",
       "      <td>0.740457</td>\n",
       "      <td>0.784455</td>\n",
       "      <td>0.822715</td>\n",
       "      <td>0.849610</td>\n",
       "      <td>0.865793</td>\n",
       "      <td>0.912621</td>\n",
       "      <td>0.957298</td>\n",
       "      <td>0.992833</td>\n",
       "      <td>1.017318</td>\n",
       "      <td>1.066549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.765355</td>\n",
       "      <td>0.810057</td>\n",
       "      <td>0.822050</td>\n",
       "      <td>0.901893</td>\n",
       "      <td>0.915998</td>\n",
       "      <td>0.910270</td>\n",
       "      <td>0.953313</td>\n",
       "      <td>1.051872</td>\n",
       "      <td>1.108253</td>\n",
       "      <td>1.101217</td>\n",
       "      <td>1.111078</td>\n",
       "      <td>1.145994</td>\n",
       "      <td>1.328691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.941207</td>\n",
       "      <td>0.998817</td>\n",
       "      <td>1.082702</td>\n",
       "      <td>1.133929</td>\n",
       "      <td>1.269883</td>\n",
       "      <td>1.297610</td>\n",
       "      <td>1.283175</td>\n",
       "      <td>1.231585</td>\n",
       "      <td>1.253561</td>\n",
       "      <td>1.338862</td>\n",
       "      <td>1.375398</td>\n",
       "      <td>1.435912</td>\n",
       "      <td>1.425041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.074037</td>\n",
       "      <td>2.204953</td>\n",
       "      <td>1.922648</td>\n",
       "      <td>1.840182</td>\n",
       "      <td>1.921905</td>\n",
       "      <td>1.980679</td>\n",
       "      <td>1.881645</td>\n",
       "      <td>1.960930</td>\n",
       "      <td>1.857206</td>\n",
       "      <td>1.745497</td>\n",
       "      <td>1.676137</td>\n",
       "      <td>1.779063</td>\n",
       "      <td>3.105663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.822299   0.921157   0.974330   1.014737   1.052366   1.083733   \n",
       "std     0.387519   0.398337   0.372758   0.358631   0.367517   0.366709   \n",
       "min     0.412711   0.444991   0.593176   0.646963   0.663596   0.675018   \n",
       "25%     0.549874   0.698068   0.712893   0.740457   0.784455   0.822715   \n",
       "50%     0.765355   0.810057   0.822050   0.901893   0.915998   0.910270   \n",
       "75%     0.941207   0.998817   1.082702   1.133929   1.269883   1.297610   \n",
       "max     2.074037   2.204953   1.922648   1.840182   1.921905   1.980679   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    1.107944   1.127696   1.150705   1.165272   1.179067   1.199488   \n",
       "std     0.358215   0.341111   0.329969   0.308926   0.293755   0.295900   \n",
       "min     0.653409   0.683681   0.734620   0.783252   0.768834   0.781345   \n",
       "25%     0.849610   0.865793   0.912621   0.957298   0.992833   1.017318   \n",
       "50%     0.953313   1.051872   1.108253   1.101217   1.111078   1.145994   \n",
       "75%     1.283175   1.231585   1.253561   1.338862   1.375398   1.435912   \n",
       "max     1.881645   1.960930   1.857206   1.745497   1.676137   1.779063   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    1.341217  \n",
       "std     0.414752  \n",
       "min     0.999604  \n",
       "25%     1.066549  \n",
       "50%     1.328691  \n",
       "75%     1.425041  \n",
       "max     3.105663  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mase\n",
    "cv_errors = forecast_errors_cv_scaled(cv_preds, cv_test, train[REGION])\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-arima_mase.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'mase'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.814815</td>\n",
       "      <td>0.780423</td>\n",
       "      <td>0.770723</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.747090</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.733938</td>\n",
       "      <td>0.727513</td>\n",
       "      <td>0.720165</td>\n",
       "      <td>0.717460</td>\n",
       "      <td>0.715729</td>\n",
       "      <td>0.711640</td>\n",
       "      <td>0.775342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.197372</td>\n",
       "      <td>0.173755</td>\n",
       "      <td>0.146496</td>\n",
       "      <td>0.135454</td>\n",
       "      <td>0.146053</td>\n",
       "      <td>0.149859</td>\n",
       "      <td>0.147435</td>\n",
       "      <td>0.137484</td>\n",
       "      <td>0.135057</td>\n",
       "      <td>0.128164</td>\n",
       "      <td>0.123223</td>\n",
       "      <td>0.124172</td>\n",
       "      <td>0.113929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.371429</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.412698</td>\n",
       "      <td>0.457143</td>\n",
       "      <td>0.506494</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.284932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.693878</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.595238</td>\n",
       "      <td>0.743836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.755102</td>\n",
       "      <td>0.767857</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>0.740260</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.813699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>0.801587</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.811688</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.846575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.871233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.814815   0.780423   0.770723   0.761905   0.747090   0.738095   \n",
       "std     0.197372   0.173755   0.146496   0.135454   0.146053   0.149859   \n",
       "min     0.285714   0.285714   0.333333   0.428571   0.371429   0.357143   \n",
       "25%     0.714286   0.750000   0.690476   0.625000   0.671429   0.702381   \n",
       "50%     0.857143   0.857143   0.809524   0.821429   0.800000   0.785714   \n",
       "75%     1.000000   0.857143   0.857143   0.857143   0.857143   0.857143   \n",
       "max     1.000000   1.000000   0.952381   0.928571   0.914286   0.904762   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.733938   0.727513   0.720165   0.717460   0.715729   0.711640   \n",
       "std     0.147435   0.137484   0.135057   0.128164   0.123223   0.124172   \n",
       "min     0.387755   0.392857   0.412698   0.457143   0.506494   0.476190   \n",
       "25%     0.693878   0.687500   0.650794   0.628571   0.597403   0.595238   \n",
       "50%     0.755102   0.767857   0.777778   0.757143   0.740260   0.750000   \n",
       "75%     0.857143   0.830357   0.801587   0.807143   0.811688   0.821429   \n",
       "max     0.897959   0.892857   0.904762   0.900000   0.896104   0.892857   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.775342  \n",
       "std     0.113929  \n",
       "min     0.284932  \n",
       "25%     0.743836  \n",
       "50%     0.813699  \n",
       "75%     0.846575  \n",
       "max     0.871233  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-arima_coverage_80.csv\n"
     ]
    }
   ],
   "source": [
    "#output 80% PI coverage\n",
    "metric = 'coverage_80'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#95% PIs\n",
    "model = ARIMAWrapper(order=(1,1,3), seasonal_order=(1,0,1,7), \n",
    "                     training_index=train.index )\n",
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.05, step=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds_95, cv_test_95, cv_intervals_95 = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.947090</td>\n",
       "      <td>0.945326</td>\n",
       "      <td>0.943122</td>\n",
       "      <td>0.938624</td>\n",
       "      <td>0.935626</td>\n",
       "      <td>0.931973</td>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.927102</td>\n",
       "      <td>0.924339</td>\n",
       "      <td>0.921597</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.936986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.093699</td>\n",
       "      <td>0.114821</td>\n",
       "      <td>0.103744</td>\n",
       "      <td>0.094106</td>\n",
       "      <td>0.087779</td>\n",
       "      <td>0.082430</td>\n",
       "      <td>0.080247</td>\n",
       "      <td>0.077791</td>\n",
       "      <td>0.071294</td>\n",
       "      <td>0.063742</td>\n",
       "      <td>0.058689</td>\n",
       "      <td>0.056033</td>\n",
       "      <td>0.036259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.791781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.923288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.945205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.970238</td>\n",
       "      <td>0.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.972603</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.962963   0.947090   0.945326   0.943122   0.938624   0.935626   \n",
       "std     0.093699   0.114821   0.103744   0.094106   0.087779   0.082430   \n",
       "min     0.571429   0.500000   0.666667   0.714286   0.742857   0.738095   \n",
       "25%     1.000000   0.928571   0.952381   0.964286   0.957143   0.869048   \n",
       "50%     1.000000   1.000000   1.000000   1.000000   0.971429   0.976190   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.931973   0.931217   0.927102   0.924339   0.921597   0.916667   \n",
       "std     0.080247   0.077791   0.071294   0.063742   0.058689   0.056033   \n",
       "min     0.775510   0.750000   0.777778   0.800000   0.818182   0.821429   \n",
       "25%     0.846939   0.857143   0.873016   0.878571   0.863636   0.869048   \n",
       "50%     0.979592   0.982143   0.968254   0.942857   0.935065   0.916667   \n",
       "75%     1.000000   0.982143   0.984127   0.985714   0.974026   0.970238   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   0.988095   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.936986  \n",
       "std     0.036259  \n",
       "min     0.791781  \n",
       "25%     0.923288  \n",
       "50%     0.945205  \n",
       "75%     0.958904  \n",
       "max     0.972603  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_coverage_95 = prediction_int_coverage_cv(cv_test_95, cv_intervals_95)\n",
    "df_95 = pd.DataFrame(cv_coverage_95)\n",
    "df_95.columns = horizons\n",
    "df_95.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-arima_coverage_95.csv\n"
     ]
    }
   ],
   "source": [
    "#output 95% PI coverage\n",
    "metric = 'coverage_95'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df_95.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambo",
   "language": "python",
   "name": "ambo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
