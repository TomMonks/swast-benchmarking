{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression with ARIMA Errors.\n",
    "\n",
    "This model is a simple Regression model with ARIMA errors.  The regression model consists of a single independent variables 'new years day'.  This is a categorical variable to model the special event on 1st Jan every year.\n",
    "\n",
    "ARIMA order is chosen by `pmdarima.auto_arima`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from forecast_tools.metrics import (mean_absolute_scaled_error, \n",
    "                                    root_mean_squared_error,\n",
    "                                    symmetric_mean_absolute_percentage_error)\n",
    "\n",
    "#auto_arima\n",
    "from pmdarima import auto_arima\n",
    "\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.11.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels as sm\n",
    "sm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.2'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pmdarima as pm\n",
    "pm.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amb_forecast.feature_engineering import (featurize_time_series,\n",
    "                                              regular_busy_calender_days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_LEVEL = '../../../results/model_selection'\n",
    "STAGE = 'stage1'\n",
    "REGION = 'Trust'\n",
    "METHOD = 'reg-arima'\n",
    "\n",
    "FILE_NAME = 'Daily_Responses_5_Years_2019_full.csv'\n",
    "\n",
    "#split training and test data.\n",
    "TEST_SPLIT_DATE = '2019-01-01'\n",
    "\n",
    "#second subdivide: train and val\n",
    "VAL_SPLIT_DATE = '2017-07-01'\n",
    "\n",
    "#discard data after 2020 due to coronavirus\n",
    "#this is the subject of a seperate study.\n",
    "DISCARD_DATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in path\n",
    "path = f'../../../data/{FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_daily_data(path, index_col, by_col, \n",
    "                           values, dayfirst=False):\n",
    "    '''\n",
    "    Daily data is stored in long format.  Read in \n",
    "    and pivot to wide format so that there is a single \n",
    "    colmumn for each regions time series.\n",
    "    '''\n",
    "    df = pd.read_csv(path, index_col=index_col, parse_dates=True, \n",
    "                     dayfirst=dayfirst)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.index.rename(str(df.index.name).lower(), inplace=True)\n",
    "    \n",
    "    clean_table = pd.pivot_table(df, values=values.lower(), \n",
    "                                 index=[index_col.lower()],\n",
    "                                 columns=[by_col.lower()], aggfunc=np.sum)\n",
    "    \n",
    "    clean_table.index.freq = 'D'\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  \n",
       "actual_dt                      \n",
       "2013-12-30  2042.0      255.0  \n",
       "2013-12-31  1996.0      260.0  \n",
       "2014-01-01  2570.0      351.0  \n",
       "2014-01-02  2013.0      258.0  \n",
       "2014-01-03  2056.0      269.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pre_process_daily_data(path, 'Actual_dt', 'ORA', 'Actual_Value', \n",
    "                               dayfirst=False)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ts_train_test_split(clean, split_date=TEST_SPLIT_DATE)\n",
    "\n",
    "#exclude data after 2020 due to coronavirus.\n",
    "test, discard = ts_train_test_split(test, split_date=DISCARD_DATE)\n",
    "\n",
    "#split into train and val AFTER creating new years day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1828, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New years day\n",
    "\n",
    "Generate a new binary categorical feature representing new years day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude interaction as point forecasts are less accurate.\n",
    "_, _, exog = featurize_time_series(train[REGION], max_lags=1, \n",
    "                                   include_interactions=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            top\n",
       "actual_dt      \n",
       "2013-12-30    0\n",
       "2013-12-31    0\n",
       "2014-01-01    1\n",
       "2014-01-02    0\n",
       "2014-01-03    0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine exog into train array for split\n",
    "train['new_year'] = exog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "      <th>new_year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  new_year  \n",
       "actual_dt                                \n",
       "2013-12-30  2042.0      255.0         0  \n",
       "2013-12-31  1996.0      260.0         0  \n",
       "2014-01-01  2570.0      351.0         1  \n",
       "2014-01-02  2013.0      258.0         0  \n",
       "2014-01-03  2056.0      269.0         0  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train split into train and validation\n",
    "train, val = ts_train_test_split(train, split_date=VAL_SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 10)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 10)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto ARIMA model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses Auto ARIMA function to select model by AIC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##only looking at Trust level.\n",
    "#auto_results = auto_arima(train[REGION], \n",
    "#                          exogenous=train['new_year'].to_numpy().reshape(-1, 1), \n",
    "#                          seasonal=True, \n",
    "#                          m=7, \n",
    "#                          n_job=-1, \n",
    "#                          suppress_warnings=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auto_results.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Out of Sample Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pmdarima version: 1.5.2\n"
     ]
    }
   ],
   "source": [
    "print(\"pmdarima version: %s\" % pm.__version__)\n",
    "#print(auto_results.order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#override if desired to test different model.\n",
    "#order = auto_results.order\n",
    "#seasonal_order = auto_results.seasonal_order\n",
    "order = (1, 1, 2)\n",
    "seasonal_order = (1, 0, 1, 7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pm.ARIMA(order=order, seasonal_order=seasonal_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ARIMA(maxiter=50, method='lbfgs', order=(1, 1, 2), out_of_sample_size=0,\n",
       "      scoring='mse', scoring_args=None, seasonal_order=(1, 0, 1, 7),\n",
       "      start_params=None, suppress_warnings=False, trend=None,\n",
       "      with_intercept=True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(y=train[REGION], \n",
    "          exogenous=train['new_year'].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2262.30505229, 2244.11424738, 2152.94249696, 2082.20896898,\n",
       "       2078.16437783])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test prediction\n",
    "model.predict(n_periods=5, \n",
    "              exogenous=val['new_year'].iloc[:5].to_numpy().reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper classes for statsmodels ARIMA\n",
    "\n",
    "Adapter/wrapper class to enable usage within standard cross validation used across all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARIMAWrapper:\n",
    "    '''\n",
    "    Facade for statsmodels ARIMA models\n",
    "    '''\n",
    "    def __init__(self, order, seasonal_order, training_index, holidays=None):\n",
    "        self._order = order\n",
    "        self._seasonal_order = seasonal_order\n",
    "        self._training_index = training_index\n",
    "        self._holidays = holidays\n",
    "\n",
    "    def _get_resids(self):\n",
    "        return self._fitted.resid\n",
    "\n",
    "    def _get_preds(self):\n",
    "        return self._fitted.fittedvalues\n",
    "    \n",
    "    def _encode_holidays(self, holidays, idx):\n",
    "        dummy = idx.isin(holidays).astype(int)\n",
    "        dummy = pd.DataFrame(dummy)\n",
    "        dummy.columns = ['holiday']\n",
    "        dummy.index = idx\n",
    "        return dummy\n",
    "\n",
    "    def fit(self, y_train):\n",
    "        \n",
    "        #extend training index\n",
    "        if len(y_train) > len(self._training_index):\n",
    "\n",
    "            self._training_index = pd.date_range(start=self._training_index[0], \n",
    "                                                 periods=len(y_train),\n",
    "                                                 freq=self._training_index.freq)\n",
    "            \n",
    "        holiday_train = None\n",
    "        if not self._holidays is None:\n",
    "            holiday_train = self._encode_holidays(self._holidays, \n",
    "                                                  self._training_index)\n",
    "    \n",
    "        \n",
    "        self._model = ARIMA(endog=y_train,\n",
    "                            exog=holiday_train,\n",
    "                            order=self._order, \n",
    "                            seasonal_order=self._seasonal_order)#,\n",
    "                            #enforce_stationarity=False)\n",
    "        \n",
    "        self._fitted = self._model.fit()\n",
    "        self._t = len(train)\n",
    "        \n",
    "    \n",
    "    def predict(self, horizon, return_conf_int=False, alpha=0.2):\n",
    "        '''\n",
    "        forecast h steps ahead.\n",
    "        \n",
    "        Params:\n",
    "        ------\n",
    "        h: int\n",
    "            h-step forecast\n",
    "        \n",
    "        return_conf_int: bool, optional (default=False)\n",
    "            return 1 - alpha PI\n",
    "        \n",
    "        alpha: float, optional (default=0.2)\n",
    "            return 1 - alpha PI\n",
    "                       \n",
    "        Returns:\n",
    "        -------\n",
    "        np.array\n",
    "            If return_conf_int = False returns preds only\n",
    "            \n",
    "        np.array, np.array\n",
    "            If return_conf_int = True returns tuple of preds, pred_ints\n",
    "        '''\n",
    "        \n",
    "        #+1 to date range then trim off the first value\n",
    "\n",
    "        f_idx = pd.date_range(start=self._training_index[-1], \n",
    "                              periods=horizon+1,\n",
    "                              freq=self._training_index.freq)[1:]\n",
    "        \n",
    "        #encode holidays if included.\n",
    "        exog_holiday = None\n",
    "        if not self._holidays is None:\n",
    "            exog_holiday = self._encode_holidays(self._holidays, f_idx)\n",
    "        \n",
    "    \n",
    "        forecast = self._fitted.get_forecast(horizon, exog=exog_holiday)\n",
    "        mean_forecast = forecast.summary_frame()['mean'].to_numpy()\n",
    "        \n",
    "        if return_conf_int:\n",
    "            df = forecast.summary_frame(alpha=alpha)\n",
    "            pi = df[['mean_ci_lower', 'mean_ci_upper']].to_numpy()\n",
    "            return mean_forecast, pi\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            return mean_forecast\n",
    "\n",
    "    fittedvalues = property(_get_preds)\n",
    "    resid = property(_get_resids)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "`time_series_cv` implements rolling forecast origin cross validation for time series.  \n",
    "It does not calculate forecast error, but instead returns the predictions, pred intervals and actuals in an array that can be passed to any forecast error function. (this is for efficiency and allows additional metrics to be calculated if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(model, train, val, horizons, alpha=0.2, step=1):\n",
    "    '''\n",
    "    Time series cross validation across multiple horizons for a single model.\n",
    "\n",
    "    Incrementally adds additional training data to the model and tests\n",
    "    across a provided list of forecast horizons. Note that function tests a\n",
    "    model only against complete validation sets.  E.g. if horizon = 15 and \n",
    "    len(val) = 12 then no testing is done.  In the case of multiple horizons\n",
    "    e.g. [7, 14, 28] then the function will use the maximum forecast horizon\n",
    "    to calculate the number of iterations i.e if len(val) = 365 and step = 1\n",
    "    then no. iterations = len(val) - max(horizon) = 365 - 28 = 337.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    model - forecasting model\n",
    "\n",
    "    train - np.array - vector of training data\n",
    "\n",
    "    val - np.array - vector of validation data\n",
    "\n",
    "    horizon - list of ints, forecast horizon e.g. [7, 14, 28] days\n",
    "    \n",
    "    alpha - float, optional (default=0.2)\n",
    "        1 - alpha prediction interval specification\n",
    "\n",
    "    step -- int, optional (default=1)\n",
    "            step taken in cross validation \n",
    "            e.g. 1 in next cross validation training data includes next point \n",
    "            from the validation set.\n",
    "            e.g. 7 in the next cross validation training data includes next 7 points\n",
    "            (default=1)\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    np.array, np.array, np.array\n",
    "        - cv_preds, cv_test, cv_intervals\n",
    "    '''\n",
    "    \n",
    "    #point forecasts\n",
    "    cv_preds = [] \n",
    "    #ground truth observations\n",
    "    cv_actuals = [] \n",
    "    #prediction intervals\n",
    "    cv_pis = []\n",
    "    \n",
    "    split = 0\n",
    "\n",
    "    print('split => ', end=\"\")\n",
    "    for i in range(0, len(val) - max(horizons) + 1, step):\n",
    "        split += 1\n",
    "        print(f'{split}, ', end=\"\")\n",
    "                \n",
    "        train_cv = np.concatenate([train, val[:i]], axis=0)\n",
    "        model.fit(train_cv)\n",
    "        \n",
    "        #predict the maximum horizon \n",
    "        preds, pis = model.predict(horizon=len(val[i:i+max(horizons)]), \n",
    "                                   return_conf_int=True,\n",
    "                                   alpha=alpha)        \n",
    "        cv_h_preds = []\n",
    "        cv_test = []\n",
    "        cv_h_pis = []\n",
    "        \n",
    "        #sub horizon calculations\n",
    "        for h in horizons:\n",
    "            #store the h-step prediction\n",
    "            cv_h_preds.append(preds[:h])\n",
    "            #store the h-step actual value\n",
    "            cv_test.append(val.iloc[i:i+h])    \n",
    "            cv_h_pis.append(pis[:h])\n",
    "                     \n",
    "        cv_preds.append(cv_h_preds)\n",
    "        cv_actuals.append(cv_test)\n",
    "        cv_pis.append(cv_h_pis)\n",
    "        \n",
    "    print('done.\\n')        \n",
    "    return cv_preds, cv_actuals, cv_pis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for calculating CV scores for point predictions and coverage.\n",
    "\n",
    "These functions have been written to work with the output of `time_series_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast error in the current split\n",
    "    \n",
    "    Params:\n",
    "    -----\n",
    "    cv_preds, np.array\n",
    "        Split predictions\n",
    "        \n",
    "    \n",
    "    cv_test: np.array\n",
    "        acutal ground truth observations\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        np.ndarray\n",
    "            cross validation errors for split\n",
    "    '''\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = error_func(cv_test[split], cv_preds[split])\n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast errors by forecast horizon\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    cv_preds: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    cv_test: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        \n",
    "    '''\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error(cv_preds[h], cv_test[h], error_func)\n",
    "        horizon_errors.append(split_errors)\n",
    "\n",
    "    return np.array(horizon_errors)\n",
    "\n",
    "def split_coverage(cv_test, cv_intervals):\n",
    "    n_splits = len(cv_test)\n",
    "    cv_errors = []\n",
    "        \n",
    "    for split in range(n_splits):\n",
    "        val = np.asarray(cv_test[split])\n",
    "        lower = cv_intervals[split].T[0]\n",
    "        upper = cv_intervals[split].T[1]\n",
    "        \n",
    "        coverage = len(np.where((val > lower) & (val < upper))[0])\n",
    "        coverage = coverage / len(val)\n",
    "        \n",
    "        cv_errors.append(coverage)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "    \n",
    "    \n",
    "def prediction_int_coverage_cv(cv_test, cv_intervals):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_intervals = np.array(cv_intervals)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_coverage = []\n",
    "    for h in range(n_horizons):\n",
    "        split_coverages = split_coverage(cv_test[h], cv_intervals[h])\n",
    "        horizon_coverage.append(split_coverages)\n",
    "\n",
    "    return np.array(horizon_coverage)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error_scaled(cv_preds, cv_test, y_train):\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = mean_absolute_scaled_error(cv_test[split], cv_preds[split], \n",
    "                                                y_train, period=7)\n",
    "        \n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv_scaled(cv_preds, cv_test, y_train):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error_scaled(cv_preds[h], cv_test[h], y_train)\n",
    "        horizon_errors.append(split_errors)\n",
    "        \n",
    "    return np.array(horizon_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run cross validation\n",
    "\n",
    "This is run twices once each for 80 and 95% prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 2)\n",
      "(1, 0, 1, 7)\n"
     ]
    }
   ],
   "source": [
    "#reminder of ARIMA order\n",
    "print(order)\n",
    "print(seasonal_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holidays included"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New years day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "exog = regular_busy_calender_days(train[REGION], quantile=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_year = pd.DataFrame({\n",
    "                         'holiday': 'new_year',\n",
    "                         'ds': pd.date_range(start=exog[0], \n",
    "                                             periods=20, \n",
    "                                             freq='YS')\n",
    "                        })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model and run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = ARIMAWrapper(order=order, seasonal_order=seasonal_order, \n",
    "                     training_index=train.index, \n",
    "                     holidays=new_year['ds'].tolist())\n",
    "\n",
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "results = time_series_cv(model, train[REGION], val[REGION], \n",
    "                         horizons, alpha=0.2, step=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## symmetric MAPE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds, cv_test, cv_intervals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.817042</td>\n",
       "      <td>3.164754</td>\n",
       "      <td>3.377149</td>\n",
       "      <td>3.531989</td>\n",
       "      <td>3.695879</td>\n",
       "      <td>3.849643</td>\n",
       "      <td>3.982054</td>\n",
       "      <td>4.088984</td>\n",
       "      <td>4.203878</td>\n",
       "      <td>4.293219</td>\n",
       "      <td>4.368358</td>\n",
       "      <td>4.448976</td>\n",
       "      <td>5.575053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.958813</td>\n",
       "      <td>0.962132</td>\n",
       "      <td>0.947362</td>\n",
       "      <td>0.880134</td>\n",
       "      <td>0.944026</td>\n",
       "      <td>0.986216</td>\n",
       "      <td>1.015735</td>\n",
       "      <td>0.980011</td>\n",
       "      <td>1.048592</td>\n",
       "      <td>1.055287</td>\n",
       "      <td>1.056161</td>\n",
       "      <td>1.146978</td>\n",
       "      <td>2.037696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.463270</td>\n",
       "      <td>1.849534</td>\n",
       "      <td>2.359003</td>\n",
       "      <td>2.465616</td>\n",
       "      <td>2.664897</td>\n",
       "      <td>2.656501</td>\n",
       "      <td>2.526379</td>\n",
       "      <td>2.645832</td>\n",
       "      <td>2.756132</td>\n",
       "      <td>2.905157</td>\n",
       "      <td>2.979387</td>\n",
       "      <td>2.990024</td>\n",
       "      <td>3.743676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.189718</td>\n",
       "      <td>2.645513</td>\n",
       "      <td>2.755919</td>\n",
       "      <td>2.970553</td>\n",
       "      <td>3.107871</td>\n",
       "      <td>3.210227</td>\n",
       "      <td>3.303151</td>\n",
       "      <td>3.490358</td>\n",
       "      <td>3.625386</td>\n",
       "      <td>3.627445</td>\n",
       "      <td>3.580980</td>\n",
       "      <td>3.595365</td>\n",
       "      <td>4.353181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.570574</td>\n",
       "      <td>2.993214</td>\n",
       "      <td>3.235118</td>\n",
       "      <td>3.387836</td>\n",
       "      <td>3.397949</td>\n",
       "      <td>3.578998</td>\n",
       "      <td>3.811569</td>\n",
       "      <td>3.862348</td>\n",
       "      <td>3.887043</td>\n",
       "      <td>4.170335</td>\n",
       "      <td>4.331648</td>\n",
       "      <td>4.318468</td>\n",
       "      <td>5.050290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.360787</td>\n",
       "      <td>3.471712</td>\n",
       "      <td>3.643612</td>\n",
       "      <td>3.817096</td>\n",
       "      <td>4.157899</td>\n",
       "      <td>4.397981</td>\n",
       "      <td>4.449756</td>\n",
       "      <td>4.542215</td>\n",
       "      <td>4.592055</td>\n",
       "      <td>4.776573</td>\n",
       "      <td>4.902100</td>\n",
       "      <td>5.026401</td>\n",
       "      <td>5.891917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.538577</td>\n",
       "      <td>6.005663</td>\n",
       "      <td>6.657392</td>\n",
       "      <td>6.526569</td>\n",
       "      <td>7.041053</td>\n",
       "      <td>7.186746</td>\n",
       "      <td>7.257271</td>\n",
       "      <td>7.035648</td>\n",
       "      <td>7.449388</td>\n",
       "      <td>7.213427</td>\n",
       "      <td>7.029521</td>\n",
       "      <td>7.463354</td>\n",
       "      <td>13.100792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    2.817042   3.164754   3.377149   3.531989   3.695879   3.849643   \n",
       "std     0.958813   0.962132   0.947362   0.880134   0.944026   0.986216   \n",
       "min     1.463270   1.849534   2.359003   2.465616   2.664897   2.656501   \n",
       "25%     2.189718   2.645513   2.755919   2.970553   3.107871   3.210227   \n",
       "50%     2.570574   2.993214   3.235118   3.387836   3.397949   3.578998   \n",
       "75%     3.360787   3.471712   3.643612   3.817096   4.157899   4.397981   \n",
       "max     5.538577   6.005663   6.657392   6.526569   7.041053   7.186746   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    3.982054   4.088984   4.203878   4.293219   4.368358   4.448976   \n",
       "std     1.015735   0.980011   1.048592   1.055287   1.056161   1.146978   \n",
       "min     2.526379   2.645832   2.756132   2.905157   2.979387   2.990024   \n",
       "25%     3.303151   3.490358   3.625386   3.627445   3.580980   3.595365   \n",
       "50%     3.811569   3.862348   3.887043   4.170335   4.331648   4.318468   \n",
       "75%     4.449756   4.542215   4.592055   4.776573   4.902100   5.026401   \n",
       "max     7.257271   7.035648   7.449388   7.213427   7.029521   7.463354   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    5.575053  \n",
       "std     2.037696  \n",
       "min     3.743676  \n",
       "25%     4.353181  \n",
       "50%     5.050290  \n",
       "75%     5.891917  \n",
       "max    13.100792  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions smape\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, \n",
    "                               symmetric_mean_absolute_percentage_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-reg-arima_smape.csv\n"
     ]
    }
   ],
   "source": [
    "#output sMAPE results to file\n",
    "metric = 'smape'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>74.379376</td>\n",
       "      <td>84.992675</td>\n",
       "      <td>91.967937</td>\n",
       "      <td>96.626805</td>\n",
       "      <td>101.417551</td>\n",
       "      <td>105.729130</td>\n",
       "      <td>109.535798</td>\n",
       "      <td>112.767167</td>\n",
       "      <td>116.084131</td>\n",
       "      <td>118.890073</td>\n",
       "      <td>121.294654</td>\n",
       "      <td>124.008786</td>\n",
       "      <td>153.554509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>25.067928</td>\n",
       "      <td>26.956111</td>\n",
       "      <td>26.990742</td>\n",
       "      <td>25.824350</td>\n",
       "      <td>26.697122</td>\n",
       "      <td>27.139625</td>\n",
       "      <td>27.640610</td>\n",
       "      <td>26.882039</td>\n",
       "      <td>28.468424</td>\n",
       "      <td>28.510738</td>\n",
       "      <td>28.437835</td>\n",
       "      <td>30.650932</td>\n",
       "      <td>48.406822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>38.074127</td>\n",
       "      <td>51.713581</td>\n",
       "      <td>63.267767</td>\n",
       "      <td>68.387649</td>\n",
       "      <td>71.872953</td>\n",
       "      <td>74.509067</td>\n",
       "      <td>72.564137</td>\n",
       "      <td>74.011975</td>\n",
       "      <td>75.259112</td>\n",
       "      <td>78.740762</td>\n",
       "      <td>82.169201</td>\n",
       "      <td>81.988381</td>\n",
       "      <td>108.684579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>58.603831</td>\n",
       "      <td>68.967503</td>\n",
       "      <td>74.296010</td>\n",
       "      <td>81.693992</td>\n",
       "      <td>85.046496</td>\n",
       "      <td>87.203760</td>\n",
       "      <td>89.340316</td>\n",
       "      <td>93.995922</td>\n",
       "      <td>99.465171</td>\n",
       "      <td>99.541410</td>\n",
       "      <td>101.672388</td>\n",
       "      <td>103.535723</td>\n",
       "      <td>127.098163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>70.301998</td>\n",
       "      <td>76.765234</td>\n",
       "      <td>85.178126</td>\n",
       "      <td>89.493967</td>\n",
       "      <td>89.627893</td>\n",
       "      <td>97.350091</td>\n",
       "      <td>105.518806</td>\n",
       "      <td>106.712349</td>\n",
       "      <td>110.973125</td>\n",
       "      <td>117.291884</td>\n",
       "      <td>121.885571</td>\n",
       "      <td>122.197493</td>\n",
       "      <td>139.470141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.445541</td>\n",
       "      <td>92.344350</td>\n",
       "      <td>91.310916</td>\n",
       "      <td>99.510305</td>\n",
       "      <td>108.258282</td>\n",
       "      <td>121.945788</td>\n",
       "      <td>129.215219</td>\n",
       "      <td>128.740601</td>\n",
       "      <td>127.810914</td>\n",
       "      <td>132.583350</td>\n",
       "      <td>135.423936</td>\n",
       "      <td>139.876795</td>\n",
       "      <td>159.012268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>155.583825</td>\n",
       "      <td>158.381710</td>\n",
       "      <td>174.160152</td>\n",
       "      <td>168.925672</td>\n",
       "      <td>180.084651</td>\n",
       "      <td>182.188267</td>\n",
       "      <td>183.652824</td>\n",
       "      <td>179.035187</td>\n",
       "      <td>189.352490</td>\n",
       "      <td>189.276479</td>\n",
       "      <td>182.503377</td>\n",
       "      <td>194.250946</td>\n",
       "      <td>335.478567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              7           14          21          28          35          42   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    74.379376   84.992675   91.967937   96.626805  101.417551  105.729130   \n",
       "std     25.067928   26.956111   26.990742   25.824350   26.697122   27.139625   \n",
       "min     38.074127   51.713581   63.267767   68.387649   71.872953   74.509067   \n",
       "25%     58.603831   68.967503   74.296010   81.693992   85.046496   87.203760   \n",
       "50%     70.301998   76.765234   85.178126   89.493967   89.627893   97.350091   \n",
       "75%     87.445541   92.344350   91.310916   99.510305  108.258282  121.945788   \n",
       "max    155.583825  158.381710  174.160152  168.925672  180.084651  182.188267   \n",
       "\n",
       "              49          56          63          70          77          84   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean   109.535798  112.767167  116.084131  118.890073  121.294654  124.008786   \n",
       "std     27.640610   26.882039   28.468424   28.510738   28.437835   30.650932   \n",
       "min     72.564137   74.011975   75.259112   78.740762   82.169201   81.988381   \n",
       "25%     89.340316   93.995922   99.465171   99.541410  101.672388  103.535723   \n",
       "50%    105.518806  106.712349  110.973125  117.291884  121.885571  122.197493   \n",
       "75%    129.215219  128.740601  127.810914  132.583350  135.423936  139.876795   \n",
       "max    183.652824  179.035187  189.352490  189.276479  182.503377  194.250946   \n",
       "\n",
       "              365  \n",
       "count   27.000000  \n",
       "mean   153.554509  \n",
       "std     48.406822  \n",
       "min    108.684579  \n",
       "25%    127.098163  \n",
       "50%    139.470141  \n",
       "75%    159.012268  \n",
       "max    335.478567  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions rmse - no interactions\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, root_mean_squared_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-reg-arima_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'rmse'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MASE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.758820</td>\n",
       "      <td>0.854923</td>\n",
       "      <td>0.914108</td>\n",
       "      <td>0.957469</td>\n",
       "      <td>1.003028</td>\n",
       "      <td>1.045750</td>\n",
       "      <td>1.082595</td>\n",
       "      <td>1.112239</td>\n",
       "      <td>1.143974</td>\n",
       "      <td>1.168610</td>\n",
       "      <td>1.189556</td>\n",
       "      <td>1.212100</td>\n",
       "      <td>1.520025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.280369</td>\n",
       "      <td>0.292226</td>\n",
       "      <td>0.291738</td>\n",
       "      <td>0.277567</td>\n",
       "      <td>0.294696</td>\n",
       "      <td>0.305287</td>\n",
       "      <td>0.311005</td>\n",
       "      <td>0.299490</td>\n",
       "      <td>0.314455</td>\n",
       "      <td>0.312985</td>\n",
       "      <td>0.309346</td>\n",
       "      <td>0.331076</td>\n",
       "      <td>0.594339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.391092</td>\n",
       "      <td>0.472348</td>\n",
       "      <td>0.594703</td>\n",
       "      <td>0.651643</td>\n",
       "      <td>0.678757</td>\n",
       "      <td>0.683521</td>\n",
       "      <td>0.647589</td>\n",
       "      <td>0.677585</td>\n",
       "      <td>0.706520</td>\n",
       "      <td>0.748448</td>\n",
       "      <td>0.774617</td>\n",
       "      <td>0.778185</td>\n",
       "      <td>1.017615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.570231</td>\n",
       "      <td>0.666615</td>\n",
       "      <td>0.716045</td>\n",
       "      <td>0.785877</td>\n",
       "      <td>0.820397</td>\n",
       "      <td>0.832725</td>\n",
       "      <td>0.879201</td>\n",
       "      <td>0.926893</td>\n",
       "      <td>0.959506</td>\n",
       "      <td>0.966033</td>\n",
       "      <td>0.991836</td>\n",
       "      <td>0.989936</td>\n",
       "      <td>1.175340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.699802</td>\n",
       "      <td>0.808350</td>\n",
       "      <td>0.840069</td>\n",
       "      <td>0.892695</td>\n",
       "      <td>0.900337</td>\n",
       "      <td>0.953938</td>\n",
       "      <td>1.053282</td>\n",
       "      <td>1.073590</td>\n",
       "      <td>1.080745</td>\n",
       "      <td>1.165237</td>\n",
       "      <td>1.177223</td>\n",
       "      <td>1.132682</td>\n",
       "      <td>1.364792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.874319</td>\n",
       "      <td>0.915400</td>\n",
       "      <td>0.962886</td>\n",
       "      <td>1.018530</td>\n",
       "      <td>1.124226</td>\n",
       "      <td>1.208289</td>\n",
       "      <td>1.239008</td>\n",
       "      <td>1.280964</td>\n",
       "      <td>1.266780</td>\n",
       "      <td>1.304038</td>\n",
       "      <td>1.352616</td>\n",
       "      <td>1.343522</td>\n",
       "      <td>1.572372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.631128</td>\n",
       "      <td>1.726549</td>\n",
       "      <td>1.898614</td>\n",
       "      <td>1.862760</td>\n",
       "      <td>2.003457</td>\n",
       "      <td>2.044160</td>\n",
       "      <td>2.062336</td>\n",
       "      <td>1.999032</td>\n",
       "      <td>2.112901</td>\n",
       "      <td>2.047065</td>\n",
       "      <td>1.998356</td>\n",
       "      <td>2.119338</td>\n",
       "      <td>3.758698</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.758820   0.854923   0.914108   0.957469   1.003028   1.045750   \n",
       "std     0.280369   0.292226   0.291738   0.277567   0.294696   0.305287   \n",
       "min     0.391092   0.472348   0.594703   0.651643   0.678757   0.683521   \n",
       "25%     0.570231   0.666615   0.716045   0.785877   0.820397   0.832725   \n",
       "50%     0.699802   0.808350   0.840069   0.892695   0.900337   0.953938   \n",
       "75%     0.874319   0.915400   0.962886   1.018530   1.124226   1.208289   \n",
       "max     1.631128   1.726549   1.898614   1.862760   2.003457   2.044160   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    1.082595   1.112239   1.143974   1.168610   1.189556   1.212100   \n",
       "std     0.311005   0.299490   0.314455   0.312985   0.309346   0.331076   \n",
       "min     0.647589   0.677585   0.706520   0.748448   0.774617   0.778185   \n",
       "25%     0.879201   0.926893   0.959506   0.966033   0.991836   0.989936   \n",
       "50%     1.053282   1.073590   1.080745   1.165237   1.177223   1.132682   \n",
       "75%     1.239008   1.280964   1.266780   1.304038   1.352616   1.343522   \n",
       "max     2.062336   1.999032   2.112901   2.047065   1.998356   2.119338   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    1.520025  \n",
       "std     0.594339  \n",
       "min     1.017615  \n",
       "25%     1.175340  \n",
       "50%     1.364792  \n",
       "75%     1.572372  \n",
       "max     3.758698  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mase\n",
    "cv_errors = forecast_errors_cv_scaled(cv_preds, cv_test, train['Trust'])\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-reg-arima_mase.csv\n"
     ]
    }
   ],
   "source": [
    "metric = 'mase'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 80% Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.804233</td>\n",
       "      <td>0.788360</td>\n",
       "      <td>0.765432</td>\n",
       "      <td>0.744709</td>\n",
       "      <td>0.722751</td>\n",
       "      <td>0.709877</td>\n",
       "      <td>0.696145</td>\n",
       "      <td>0.691138</td>\n",
       "      <td>0.686067</td>\n",
       "      <td>0.679365</td>\n",
       "      <td>0.677730</td>\n",
       "      <td>0.673721</td>\n",
       "      <td>0.728463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.177848</td>\n",
       "      <td>0.162739</td>\n",
       "      <td>0.148206</td>\n",
       "      <td>0.137860</td>\n",
       "      <td>0.141047</td>\n",
       "      <td>0.144230</td>\n",
       "      <td>0.144677</td>\n",
       "      <td>0.140242</td>\n",
       "      <td>0.146364</td>\n",
       "      <td>0.149690</td>\n",
       "      <td>0.147286</td>\n",
       "      <td>0.156104</td>\n",
       "      <td>0.155323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.257143</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.244898</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.271429</td>\n",
       "      <td>0.311688</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.205479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.626984</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.616883</td>\n",
       "      <td>0.577381</td>\n",
       "      <td>0.639726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.696429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.701299</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.750685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.806122</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.807143</td>\n",
       "      <td>0.805195</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.842466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.844156</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.915068</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.804233   0.788360   0.765432   0.744709   0.722751   0.709877   \n",
       "std     0.177848   0.162739   0.148206   0.137860   0.141047   0.144230   \n",
       "min     0.428571   0.285714   0.285714   0.321429   0.257143   0.238095   \n",
       "25%     0.714286   0.714286   0.738095   0.678571   0.657143   0.642857   \n",
       "50%     0.857143   0.785714   0.809524   0.785714   0.771429   0.714286   \n",
       "75%     1.000000   0.892857   0.857143   0.839286   0.828571   0.833333   \n",
       "max     1.000000   1.000000   0.904762   0.892857   0.914286   0.880952   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.696145   0.691138   0.686067   0.679365   0.677730   0.673721   \n",
       "std     0.144677   0.140242   0.146364   0.149690   0.147286   0.156104   \n",
       "min     0.244898   0.267857   0.238095   0.271429   0.311688   0.285714   \n",
       "25%     0.642857   0.642857   0.626984   0.614286   0.616883   0.577381   \n",
       "50%     0.714286   0.696429   0.714286   0.685714   0.701299   0.690476   \n",
       "75%     0.806122   0.785714   0.793651   0.807143   0.805195   0.797619   \n",
       "max     0.877551   0.875000   0.888889   0.871429   0.844156   0.857143   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.728463  \n",
       "std     0.155323  \n",
       "min     0.205479  \n",
       "25%     0.639726  \n",
       "50%     0.750685  \n",
       "75%     0.842466  \n",
       "max     0.915068  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-reg-arima_coverage_80.csv\n"
     ]
    }
   ],
   "source": [
    "#write 80% coverage to file\n",
    "metric = 'coverage_80'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Repeat for 95% PIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#95% PIs\n",
    "model = ARIMAWrapper(order=order, seasonal_order=seasonal_order, \n",
    "                     training_index=train.index, \n",
    "                     holidays=new_year['ds'].tolist())\n",
    "\n",
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "results = time_series_cv(model, train[REGION], val[REGION], \n",
    "                         horizons, alpha=0.05, step=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 95% coverage results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds, cv_test, cv_intervals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.939153</td>\n",
       "      <td>0.929453</td>\n",
       "      <td>0.929894</td>\n",
       "      <td>0.922751</td>\n",
       "      <td>0.914462</td>\n",
       "      <td>0.908541</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.893004</td>\n",
       "      <td>0.887831</td>\n",
       "      <td>0.882155</td>\n",
       "      <td>0.878307</td>\n",
       "      <td>0.909285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.075099</td>\n",
       "      <td>0.111546</td>\n",
       "      <td>0.113896</td>\n",
       "      <td>0.100275</td>\n",
       "      <td>0.104172</td>\n",
       "      <td>0.103206</td>\n",
       "      <td>0.092553</td>\n",
       "      <td>0.083366</td>\n",
       "      <td>0.093346</td>\n",
       "      <td>0.090064</td>\n",
       "      <td>0.091685</td>\n",
       "      <td>0.100492</td>\n",
       "      <td>0.062361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.551020</td>\n",
       "      <td>0.607143</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.614286</td>\n",
       "      <td>0.649351</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.734247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.866071</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.845238</td>\n",
       "      <td>0.863014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.923288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.969863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.978082</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.962963   0.939153   0.929453   0.929894   0.922751   0.914462   \n",
       "std     0.075099   0.111546   0.113896   0.100275   0.104172   0.103206   \n",
       "min     0.714286   0.571429   0.523810   0.571429   0.514286   0.500000   \n",
       "25%     1.000000   0.928571   0.904762   0.928571   0.900000   0.880952   \n",
       "50%     1.000000   1.000000   0.952381   0.964286   0.942857   0.928571   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   0.976190   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.908541   0.902778   0.893004   0.887831   0.882155   0.878307   \n",
       "std     0.092553   0.083366   0.093346   0.090064   0.091685   0.100492   \n",
       "min     0.551020   0.607143   0.571429   0.614286   0.649351   0.642857   \n",
       "25%     0.857143   0.866071   0.857143   0.857143   0.857143   0.845238   \n",
       "50%     0.938776   0.910714   0.904762   0.900000   0.896104   0.904762   \n",
       "75%     0.979592   0.964286   0.968254   0.950000   0.948052   0.952381   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.909285  \n",
       "std     0.062361  \n",
       "min     0.734247  \n",
       "25%     0.863014  \n",
       "50%     0.923288  \n",
       "75%     0.969863  \n",
       "max     0.978082  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-reg-arima_coverage_95.csv\n"
     ]
    }
   ],
   "source": [
    "#write 95% coverage to file\n",
    "metric = 'coverage_95'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
