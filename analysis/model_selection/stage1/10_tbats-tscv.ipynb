{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation TBATS \n",
    "\n",
    "**Trigonometric seasonality, Box-Cox transformation, ARIMA errors, Trend and Seasonal components**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#forecast error metrics\n",
    "from forecast_tools.metrics import (mean_absolute_scaled_error, \n",
    "                                    root_mean_squared_error,\n",
    "                                    symmetric_mean_absolute_percentage_error)\n",
    "\n",
    "from tbats import TBATS, BATS\n",
    "\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from amb_forecast.feature_engineering import featurize_time_series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "The constants `TOP_LEVEL`, `STAGE`, `REGION`,`TRUST` and `METHOD` are used to control data selection and the directory for outputting results.  \n",
    "\n",
    "> Output file is `f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv'.csv`.  where metric will be smape, rmse, mase, coverage_80 and coverage_95. Note: `REGION`: is also used to select the correct data from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_LEVEL = '../../../results/model_selection'\n",
    "STAGE = 'stage1'\n",
    "REGION = 'Trust'\n",
    "METHOD = 'tbats'\n",
    "\n",
    "FILE_NAME = 'Daily_Responses_5_Years_2019_full.csv'\n",
    "\n",
    "#split training and test data.\n",
    "TEST_SPLIT_DATE = '2019-01-01'\n",
    "\n",
    "#second subdivide: train and val\n",
    "VAL_SPLIT_DATE = '2017-07-01'\n",
    "\n",
    "#discard data after 2020 due to coronavirus\n",
    "#this is the subject of a seperate study.\n",
    "DISCARD_DATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in path\n",
    "path = f'../../../data/{FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_daily_data(path, index_col, by_col, \n",
    "                           values, dayfirst=False):\n",
    "    '''\n",
    "    Daily data is stored in long format.  Read in \n",
    "    and pivot to wide format so that there is a single \n",
    "    colmumn for each regions time series.\n",
    "    '''\n",
    "    df = pd.read_csv(path, index_col=index_col, parse_dates=True, \n",
    "                     dayfirst=dayfirst)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.index.rename(str(df.index.name).lower(), inplace=True)\n",
    "    \n",
    "    clean_table = pd.pivot_table(df, values=values.lower(), \n",
    "                                 index=[index_col.lower()],\n",
    "                                 columns=[by_col.lower()], aggfunc=np.sum)\n",
    "    \n",
    "    clean_table.index.freq = 'D'\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  \n",
       "actual_dt                      \n",
       "2013-12-30  2042.0      255.0  \n",
       "2013-12-31  1996.0      260.0  \n",
       "2014-01-01  2570.0      351.0  \n",
       "2014-01-02  2013.0      258.0  \n",
       "2014-01-03  2056.0      269.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pre_process_daily_data(path, 'Actual_dt', 'ORA', 'Actual_Value', \n",
    "                               dayfirst=False)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ts_train_test_split(clean, split_date=TEST_SPLIT_DATE)\n",
    "\n",
    "#exclude data after 2020 due to coronavirus.\n",
    "test, discard = ts_train_test_split(test, split_date=DISCARD_DATE)\n",
    "\n",
    "#train split into train and validation\n",
    "train, val = ts_train_test_split(train, split_date=VAL_SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation\n",
    "\n",
    "`time_series_cv` implements rolling forecast origin cross validation for time series.  \n",
    "It does not calculate forecast error, but instead returns the predictions, pred intervals and actuals in an array that can be passed to any forecast error function. (this is for efficiency and allows additional metrics to be calculated if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(model, y_train, y_val, horizons, cl=0.80, \n",
    "                   step=1):\n",
    "    '''\n",
    "    Time series cross validation across multiple horizons for a single tbats \n",
    "    model.\n",
    "\n",
    "    Incrementally adds additional training data to the model and tests\n",
    "    across a provided list of forecast horizons. Note that function tests a\n",
    "    model only against complete validation sets.  E.g. if horizon = 15 and \n",
    "    len(val) = 12 then no testing is done.  In the case of multiple horizons\n",
    "    e.g. [7, 14, 28] then the function will use the maximum forecast horizon\n",
    "    to calculate the number of iterations i.e if len(val) = 365 and step = 1\n",
    "    then no. iterations = len(val) - max(horizon) = 365 - 28 = 337.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    model: fitted tbats model\n",
    "\n",
    "    y_train: np.array\n",
    "        vector of y training data\n",
    "        \n",
    "    X_train: array-like\n",
    "        matrix of X training data\n",
    "\n",
    "    y_val: np.array\n",
    "        vector of y validation data\n",
    "        \n",
    "    X_val: array-like\n",
    "        matrix of X validation data\n",
    "\n",
    "    horizon: list of ints, \n",
    "        forecast horizon e.g. [7, 14, 28] days\n",
    "\n",
    "    step : int, optional (default=1)\n",
    "        step taken in cross validation \n",
    "        e.g. 1 in next cross validation training data includes next point \n",
    "        from the validation set.\n",
    "        e.g. 7 in the next cross validation training data includes next 7 points\n",
    "        \n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    tuple: np.ndarray, np.ndarray, np.ndarray    \n",
    "        predictions, validation_set, prediction_intervals\n",
    "    '''\n",
    "    cv_preds = [] #mean forecast\n",
    "    cv_actuals = [] # actuals \n",
    "    cv_pis = [] #prediction intervals\n",
    "    split = 0\n",
    "\n",
    "    print('split => ', end=\"\")\n",
    "    \n",
    "    for i in range(0, len(val) - max(horizons) + 1, step):\n",
    "        split += 1\n",
    "        print(f'{split}, ', end=\"\")\n",
    "        \n",
    "        if i > 0:\n",
    "            #create new training y value and exogenous variables\n",
    "            y_train_cv = np.concatenate([y_train.iloc[:], \n",
    "                                         y_val.iloc[:i]], axis=0)   \n",
    "\n",
    "            #refits tbats model - it does not change model parameters\n",
    "            model.fit(y_train_cv)\n",
    "                \n",
    "        #max forecast horizon\n",
    "        horizon=len(y_val[i:i+max(horizons)])\n",
    "                \n",
    "        #predict the maximum horizon        \n",
    "        preds, pis = fitted_model.forecast(steps=horizon, \n",
    "                                           confidence_level=cl)\n",
    "\n",
    "        \n",
    "        cv_h_preds = []\n",
    "        cv_test = []\n",
    "        cv_h_pis = []\n",
    "        \n",
    "        for h in horizons:\n",
    "            #store the h-step prediction\n",
    "            cv_h_preds.append(preds[:h])\n",
    "            #store the h-step actual value\n",
    "            cv_test.append(y_val.iloc[i:i+h])    \n",
    "            \n",
    "            #pis is a dictionary 'lower_bound' and 'upper_bound'\n",
    "            lower = pis['lower_bound'][:h]\n",
    "            upper = pis['upper_bound'][:h]\n",
    "            cv_h_pis.append(np.vstack([lower, upper]).T)\n",
    "                     \n",
    "        cv_preds.append(cv_h_preds)\n",
    "        cv_actuals.append(cv_test)\n",
    "        cv_pis.append(cv_h_pis)\n",
    "        \n",
    "    print('done.\\n')        \n",
    "    return cv_preds, cv_actuals, cv_pis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for calculating CV scores for point predictions and coverage.\n",
    "\n",
    "These functions have been written to work with the output of `time_series_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast error in the current split\n",
    "    \n",
    "    Params:\n",
    "    -----\n",
    "    cv_preds, np.array\n",
    "        Split predictions\n",
    "        \n",
    "    \n",
    "    cv_test: np.array\n",
    "        acutal ground truth observations\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        np.ndarray\n",
    "            cross validation errors for split\n",
    "    '''\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = error_func(cv_test[split], cv_preds[split])\n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast errors by forecast horizon\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    cv_preds: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    cv_test: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        \n",
    "    '''\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error(cv_preds[h], cv_test[h], error_func)\n",
    "        horizon_errors.append(split_errors)\n",
    "\n",
    "    return np.array(horizon_errors)\n",
    "\n",
    "def split_coverage(cv_test, cv_intervals):\n",
    "    n_splits = len(cv_test)\n",
    "    cv_errors = []\n",
    "        \n",
    "    for split in range(n_splits):\n",
    "        val = np.asarray(cv_test[split])\n",
    "        lower = cv_intervals[split].T[0]\n",
    "        upper = cv_intervals[split].T[1]\n",
    "        \n",
    "        coverage = len(np.where((val > lower) & (val < upper))[0])\n",
    "        coverage = coverage / len(val)\n",
    "        \n",
    "        cv_errors.append(coverage)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "    \n",
    "    \n",
    "def prediction_int_coverage_cv(cv_test, cv_intervals):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_intervals = np.array(cv_intervals)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_coverage = []\n",
    "    for h in range(n_horizons):\n",
    "        split_coverages = split_coverage(cv_test[h], cv_intervals[h])\n",
    "        horizon_coverage.append(split_coverages)\n",
    "\n",
    "    return np.array(horizon_coverage)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error_scaled(cv_preds, cv_test, y_train):\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = mean_absolute_scaled_error(cv_test[split], cv_preds[split], \n",
    "                                                y_train, period=7)\n",
    "        \n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv_scaled(cv_preds, cv_test, y_train):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error_scaled(cv_preds[h], cv_test[h], y_train)\n",
    "        horizon_errors.append(split_errors)\n",
    "        \n",
    "    return np.array(horizon_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TBATS fitting code\n",
    "\n",
    "TBATS library provides an autofitting function.  (Parrallel fitting seems v.slow as noted on GitHub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tbats_fitted(y_train):\n",
    "    '''\n",
    "    Return an automatically selected TBATS model.\n",
    "    '''\n",
    "    print('Selecting model...', end=' ')\n",
    "    \n",
    "    #monitor time taken\n",
    "    t0 = time.time()\n",
    "    \n",
    "    # Create estimator\n",
    "    estimator = TBATS(\n",
    "        seasonal_periods=[7, 365.25],\n",
    "        use_arma_errors=None,  \n",
    "        use_box_cox=None,\n",
    "        n_jobs=1\n",
    "    )\n",
    "    \n",
    "    fitted_model = estimator.fit(y_train)\n",
    "    \n",
    "    t1 = time.time()\n",
    "    diff = t1 - t0\n",
    "    print(f'Time taken: {(diff/60)}')\n",
    "    return fitted_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model... Time taken: 0.9235448837280273\n"
     ]
    }
   ],
   "source": [
    "fitted_model = get_tbats_fitted(train['Trust'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20258.57405232195\n",
      "0.3509404115540468\n",
      "None\n",
      "[ 8.90428788e+00  1.25886028e-02 -1.58621366e-02  4.38648047e-03\n",
      " -6.51350239e-02 -8.01599634e-03  6.59174861e-03  1.39231962e-02\n",
      " -6.20978421e-03]\n",
      "True\n",
      "[3 1]\n"
     ]
    }
   ],
   "source": [
    "# Time series analysis\n",
    "print(fitted_model.aic)\n",
    "\n",
    "# Reading model parameters\n",
    "print(fitted_model.params.alpha)\n",
    "print(fitted_model.params.beta)\n",
    "print(fitted_model.params.x0)\n",
    "print(fitted_model.params.components.use_box_cox)\n",
    "print(fitted_model.params.components.seasonal_harmonics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Cross Validation\n",
    "\n",
    "This is run twices once each for 80 and 95% prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cross-validation...\n",
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "print('cross-validation...')\n",
    "#results with 80% CI\n",
    "results = time_series_cv(fitted_model,\n",
    "                         y_train=train[REGION], \n",
    "                         y_val=val[REGION], \n",
    "                         horizons=horizons, \n",
    "                         step=7,\n",
    "                         cl=0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_preds, cv_test, cv_intervals = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.118396</td>\n",
       "      <td>3.478986</td>\n",
       "      <td>3.705974</td>\n",
       "      <td>3.851662</td>\n",
       "      <td>4.024748</td>\n",
       "      <td>4.185049</td>\n",
       "      <td>4.288618</td>\n",
       "      <td>4.358313</td>\n",
       "      <td>4.438718</td>\n",
       "      <td>4.492199</td>\n",
       "      <td>4.524415</td>\n",
       "      <td>4.558134</td>\n",
       "      <td>5.037421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.040038</td>\n",
       "      <td>2.163380</td>\n",
       "      <td>2.355032</td>\n",
       "      <td>2.368982</td>\n",
       "      <td>2.407840</td>\n",
       "      <td>2.437763</td>\n",
       "      <td>2.431798</td>\n",
       "      <td>2.386344</td>\n",
       "      <td>2.333106</td>\n",
       "      <td>2.289512</td>\n",
       "      <td>2.208013</td>\n",
       "      <td>2.128884</td>\n",
       "      <td>1.766803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.081646</td>\n",
       "      <td>1.376828</td>\n",
       "      <td>1.909551</td>\n",
       "      <td>1.889062</td>\n",
       "      <td>1.962738</td>\n",
       "      <td>2.297724</td>\n",
       "      <td>2.244062</td>\n",
       "      <td>2.249422</td>\n",
       "      <td>2.337106</td>\n",
       "      <td>2.400585</td>\n",
       "      <td>2.533608</td>\n",
       "      <td>2.757034</td>\n",
       "      <td>3.244951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.051708</td>\n",
       "      <td>2.328081</td>\n",
       "      <td>2.691733</td>\n",
       "      <td>2.800568</td>\n",
       "      <td>2.855692</td>\n",
       "      <td>3.056741</td>\n",
       "      <td>2.974578</td>\n",
       "      <td>3.182439</td>\n",
       "      <td>3.198898</td>\n",
       "      <td>3.456824</td>\n",
       "      <td>3.557360</td>\n",
       "      <td>3.672779</td>\n",
       "      <td>3.498451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.304348</td>\n",
       "      <td>2.793041</td>\n",
       "      <td>2.991741</td>\n",
       "      <td>3.180568</td>\n",
       "      <td>3.263182</td>\n",
       "      <td>3.560579</td>\n",
       "      <td>3.606964</td>\n",
       "      <td>3.735272</td>\n",
       "      <td>3.826104</td>\n",
       "      <td>3.898857</td>\n",
       "      <td>3.955488</td>\n",
       "      <td>3.917913</td>\n",
       "      <td>4.651977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.536241</td>\n",
       "      <td>3.746939</td>\n",
       "      <td>3.478040</td>\n",
       "      <td>3.936475</td>\n",
       "      <td>4.344410</td>\n",
       "      <td>4.417290</td>\n",
       "      <td>4.800781</td>\n",
       "      <td>4.688025</td>\n",
       "      <td>4.532958</td>\n",
       "      <td>4.471733</td>\n",
       "      <td>4.499636</td>\n",
       "      <td>4.797826</td>\n",
       "      <td>5.800768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>11.280364</td>\n",
       "      <td>11.628651</td>\n",
       "      <td>13.202335</td>\n",
       "      <td>13.830877</td>\n",
       "      <td>14.187979</td>\n",
       "      <td>14.515391</td>\n",
       "      <td>14.628611</td>\n",
       "      <td>14.523720</td>\n",
       "      <td>14.230642</td>\n",
       "      <td>14.389750</td>\n",
       "      <td>14.256715</td>\n",
       "      <td>13.796030</td>\n",
       "      <td>9.712243</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    3.118396   3.478986   3.705974   3.851662   4.024748   4.185049   \n",
       "std     2.040038   2.163380   2.355032   2.368982   2.407840   2.437763   \n",
       "min     1.081646   1.376828   1.909551   1.889062   1.962738   2.297724   \n",
       "25%     2.051708   2.328081   2.691733   2.800568   2.855692   3.056741   \n",
       "50%     2.304348   2.793041   2.991741   3.180568   3.263182   3.560579   \n",
       "75%     3.536241   3.746939   3.478040   3.936475   4.344410   4.417290   \n",
       "max    11.280364  11.628651  13.202335  13.830877  14.187979  14.515391   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    4.288618   4.358313   4.438718   4.492199   4.524415   4.558134   \n",
       "std     2.431798   2.386344   2.333106   2.289512   2.208013   2.128884   \n",
       "min     2.244062   2.249422   2.337106   2.400585   2.533608   2.757034   \n",
       "25%     2.974578   3.182439   3.198898   3.456824   3.557360   3.672779   \n",
       "50%     3.606964   3.735272   3.826104   3.898857   3.955488   3.917913   \n",
       "75%     4.800781   4.688025   4.532958   4.471733   4.499636   4.797826   \n",
       "max    14.628611  14.523720  14.230642  14.389750  14.256715  13.796030   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    5.037421  \n",
       "std     1.766803  \n",
       "min     3.244951  \n",
       "25%     3.498451  \n",
       "50%     4.651977  \n",
       "75%     5.800768  \n",
       "max     9.712243  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions smape\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, \n",
    "                               symmetric_mean_absolute_percentage_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-tbats_smape.csv\n"
     ]
    }
   ],
   "source": [
    "#output sMAPE results to file\n",
    "metric = 'smape'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>82.983805</td>\n",
       "      <td>94.064381</td>\n",
       "      <td>102.129947</td>\n",
       "      <td>106.985513</td>\n",
       "      <td>112.475849</td>\n",
       "      <td>117.285268</td>\n",
       "      <td>120.609777</td>\n",
       "      <td>123.020672</td>\n",
       "      <td>125.672639</td>\n",
       "      <td>127.885187</td>\n",
       "      <td>129.604117</td>\n",
       "      <td>131.428693</td>\n",
       "      <td>141.956597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.418932</td>\n",
       "      <td>57.130835</td>\n",
       "      <td>60.694500</td>\n",
       "      <td>60.507306</td>\n",
       "      <td>60.474579</td>\n",
       "      <td>60.294821</td>\n",
       "      <td>59.590248</td>\n",
       "      <td>58.784411</td>\n",
       "      <td>57.526844</td>\n",
       "      <td>55.815658</td>\n",
       "      <td>53.105494</td>\n",
       "      <td>51.092823</td>\n",
       "      <td>39.446029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>31.227766</td>\n",
       "      <td>40.711768</td>\n",
       "      <td>52.348866</td>\n",
       "      <td>53.953017</td>\n",
       "      <td>54.742817</td>\n",
       "      <td>65.101428</td>\n",
       "      <td>62.974008</td>\n",
       "      <td>62.817504</td>\n",
       "      <td>65.497106</td>\n",
       "      <td>66.043871</td>\n",
       "      <td>68.954013</td>\n",
       "      <td>74.923231</td>\n",
       "      <td>102.709451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.540088</td>\n",
       "      <td>61.457877</td>\n",
       "      <td>72.113493</td>\n",
       "      <td>74.890680</td>\n",
       "      <td>76.549440</td>\n",
       "      <td>82.061168</td>\n",
       "      <td>82.449512</td>\n",
       "      <td>86.932858</td>\n",
       "      <td>87.740078</td>\n",
       "      <td>94.401603</td>\n",
       "      <td>98.024229</td>\n",
       "      <td>101.270189</td>\n",
       "      <td>108.829968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>67.496017</td>\n",
       "      <td>76.588213</td>\n",
       "      <td>80.220964</td>\n",
       "      <td>84.038570</td>\n",
       "      <td>90.437406</td>\n",
       "      <td>98.243727</td>\n",
       "      <td>99.964287</td>\n",
       "      <td>98.760449</td>\n",
       "      <td>108.163176</td>\n",
       "      <td>113.686750</td>\n",
       "      <td>120.813285</td>\n",
       "      <td>125.102942</td>\n",
       "      <td>131.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>89.391156</td>\n",
       "      <td>101.446400</td>\n",
       "      <td>101.221587</td>\n",
       "      <td>106.578390</td>\n",
       "      <td>123.026426</td>\n",
       "      <td>137.555095</td>\n",
       "      <td>146.943049</td>\n",
       "      <td>147.006988</td>\n",
       "      <td>141.184462</td>\n",
       "      <td>141.372404</td>\n",
       "      <td>138.854937</td>\n",
       "      <td>145.124738</td>\n",
       "      <td>158.341746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>270.024504</td>\n",
       "      <td>281.117429</td>\n",
       "      <td>318.655096</td>\n",
       "      <td>332.742596</td>\n",
       "      <td>339.360831</td>\n",
       "      <td>345.705562</td>\n",
       "      <td>347.559183</td>\n",
       "      <td>345.822898</td>\n",
       "      <td>339.763888</td>\n",
       "      <td>342.757890</td>\n",
       "      <td>339.444618</td>\n",
       "      <td>330.763551</td>\n",
       "      <td>251.993047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              7           14          21          28          35          42   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    82.983805   94.064381  102.129947  106.985513  112.475849  117.285268   \n",
       "std     52.418932   57.130835   60.694500   60.507306   60.474579   60.294821   \n",
       "min     31.227766   40.711768   52.348866   53.953017   54.742817   65.101428   \n",
       "25%     54.540088   61.457877   72.113493   74.890680   76.549440   82.061168   \n",
       "50%     67.496017   76.588213   80.220964   84.038570   90.437406   98.243727   \n",
       "75%     89.391156  101.446400  101.221587  106.578390  123.026426  137.555095   \n",
       "max    270.024504  281.117429  318.655096  332.742596  339.360831  345.705562   \n",
       "\n",
       "              49          56          63          70          77          84   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean   120.609777  123.020672  125.672639  127.885187  129.604117  131.428693   \n",
       "std     59.590248   58.784411   57.526844   55.815658   53.105494   51.092823   \n",
       "min     62.974008   62.817504   65.497106   66.043871   68.954013   74.923231   \n",
       "25%     82.449512   86.932858   87.740078   94.401603   98.024229  101.270189   \n",
       "50%     99.964287   98.760449  108.163176  113.686750  120.813285  125.102942   \n",
       "75%    146.943049  147.006988  141.184462  141.372404  138.854937  145.124738   \n",
       "max    347.559183  345.822898  339.763888  342.757890  339.444618  330.763551   \n",
       "\n",
       "              365  \n",
       "count   27.000000  \n",
       "mean   141.956597  \n",
       "std     39.446029  \n",
       "min    102.709451  \n",
       "25%    108.829968  \n",
       "50%    131.109700  \n",
       "75%    158.341746  \n",
       "max    251.993047  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions rmse\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, root_mean_squared_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-tbats_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'rmse'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.846507</td>\n",
       "      <td>0.947277</td>\n",
       "      <td>1.011246</td>\n",
       "      <td>1.052642</td>\n",
       "      <td>1.101001</td>\n",
       "      <td>1.145930</td>\n",
       "      <td>1.175216</td>\n",
       "      <td>1.194743</td>\n",
       "      <td>1.216950</td>\n",
       "      <td>1.231791</td>\n",
       "      <td>1.241157</td>\n",
       "      <td>1.250913</td>\n",
       "      <td>1.366064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.593904</td>\n",
       "      <td>0.629908</td>\n",
       "      <td>0.676986</td>\n",
       "      <td>0.678552</td>\n",
       "      <td>0.687344</td>\n",
       "      <td>0.693534</td>\n",
       "      <td>0.690023</td>\n",
       "      <td>0.676473</td>\n",
       "      <td>0.660701</td>\n",
       "      <td>0.645697</td>\n",
       "      <td>0.621569</td>\n",
       "      <td>0.599348</td>\n",
       "      <td>0.490658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.306426</td>\n",
       "      <td>0.395045</td>\n",
       "      <td>0.513961</td>\n",
       "      <td>0.509636</td>\n",
       "      <td>0.531234</td>\n",
       "      <td>0.618560</td>\n",
       "      <td>0.604709</td>\n",
       "      <td>0.607521</td>\n",
       "      <td>0.631662</td>\n",
       "      <td>0.649666</td>\n",
       "      <td>0.686952</td>\n",
       "      <td>0.750497</td>\n",
       "      <td>0.885453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.546546</td>\n",
       "      <td>0.611534</td>\n",
       "      <td>0.695993</td>\n",
       "      <td>0.744093</td>\n",
       "      <td>0.753146</td>\n",
       "      <td>0.781787</td>\n",
       "      <td>0.773584</td>\n",
       "      <td>0.836882</td>\n",
       "      <td>0.873508</td>\n",
       "      <td>0.924679</td>\n",
       "      <td>0.962729</td>\n",
       "      <td>0.984586</td>\n",
       "      <td>0.951883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.614936</td>\n",
       "      <td>0.749045</td>\n",
       "      <td>0.802970</td>\n",
       "      <td>0.820078</td>\n",
       "      <td>0.850225</td>\n",
       "      <td>0.920143</td>\n",
       "      <td>0.953109</td>\n",
       "      <td>1.022520</td>\n",
       "      <td>1.069379</td>\n",
       "      <td>1.074298</td>\n",
       "      <td>1.121330</td>\n",
       "      <td>1.062427</td>\n",
       "      <td>1.273287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.915047</td>\n",
       "      <td>0.994084</td>\n",
       "      <td>0.914467</td>\n",
       "      <td>1.037152</td>\n",
       "      <td>1.226360</td>\n",
       "      <td>1.249803</td>\n",
       "      <td>1.357895</td>\n",
       "      <td>1.307838</td>\n",
       "      <td>1.268921</td>\n",
       "      <td>1.258400</td>\n",
       "      <td>1.276682</td>\n",
       "      <td>1.346927</td>\n",
       "      <td>1.569261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.165265</td>\n",
       "      <td>3.251775</td>\n",
       "      <td>3.667990</td>\n",
       "      <td>3.834274</td>\n",
       "      <td>3.926229</td>\n",
       "      <td>4.008726</td>\n",
       "      <td>4.039435</td>\n",
       "      <td>4.011978</td>\n",
       "      <td>3.930078</td>\n",
       "      <td>3.970246</td>\n",
       "      <td>3.935699</td>\n",
       "      <td>3.812895</td>\n",
       "      <td>2.723250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.846507   0.947277   1.011246   1.052642   1.101001   1.145930   \n",
       "std     0.593904   0.629908   0.676986   0.678552   0.687344   0.693534   \n",
       "min     0.306426   0.395045   0.513961   0.509636   0.531234   0.618560   \n",
       "25%     0.546546   0.611534   0.695993   0.744093   0.753146   0.781787   \n",
       "50%     0.614936   0.749045   0.802970   0.820078   0.850225   0.920143   \n",
       "75%     0.915047   0.994084   0.914467   1.037152   1.226360   1.249803   \n",
       "max     3.165265   3.251775   3.667990   3.834274   3.926229   4.008726   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    1.175216   1.194743   1.216950   1.231791   1.241157   1.250913   \n",
       "std     0.690023   0.676473   0.660701   0.645697   0.621569   0.599348   \n",
       "min     0.604709   0.607521   0.631662   0.649666   0.686952   0.750497   \n",
       "25%     0.773584   0.836882   0.873508   0.924679   0.962729   0.984586   \n",
       "50%     0.953109   1.022520   1.069379   1.074298   1.121330   1.062427   \n",
       "75%     1.357895   1.307838   1.268921   1.258400   1.276682   1.346927   \n",
       "max     4.039435   4.011978   3.930078   3.970246   3.935699   3.812895   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    1.366064  \n",
       "std     0.490658  \n",
       "min     0.885453  \n",
       "25%     0.951883  \n",
       "50%     1.273287  \n",
       "75%     1.569261  \n",
       "max     2.723250  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mase\n",
    "cv_errors = forecast_errors_cv_scaled(cv_preds, cv_test, train[REGION])\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-tbats_mase.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'mase'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.846561</td>\n",
       "      <td>0.858907</td>\n",
       "      <td>0.871693</td>\n",
       "      <td>0.877249</td>\n",
       "      <td>0.886243</td>\n",
       "      <td>0.891912</td>\n",
       "      <td>0.896825</td>\n",
       "      <td>0.902998</td>\n",
       "      <td>0.906349</td>\n",
       "      <td>0.911977</td>\n",
       "      <td>0.917108</td>\n",
       "      <td>0.976966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.225297</td>\n",
       "      <td>0.229072</td>\n",
       "      <td>0.221188</td>\n",
       "      <td>0.210185</td>\n",
       "      <td>0.208578</td>\n",
       "      <td>0.202498</td>\n",
       "      <td>0.198011</td>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.179006</td>\n",
       "      <td>0.178707</td>\n",
       "      <td>0.169074</td>\n",
       "      <td>0.155727</td>\n",
       "      <td>0.034972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.079365</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.116883</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.813699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.901786</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.982192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.957143</td>\n",
       "      <td>0.948052</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.986301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.978571</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.989041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.994521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.841270   0.846561   0.858907   0.871693   0.877249   0.886243   \n",
       "std     0.225297   0.229072   0.221188   0.210185   0.208578   0.202498   \n",
       "min     0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "25%     0.785714   0.821429   0.857143   0.875000   0.871429   0.880952   \n",
       "50%     0.857143   0.928571   0.952381   0.928571   0.942857   0.952381   \n",
       "75%     1.000000   1.000000   0.952381   0.964286   0.971429   0.976190   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.891912   0.896825   0.902998   0.906349   0.911977   0.917108   \n",
       "std     0.198011   0.191005   0.179006   0.178707   0.169074   0.155727   \n",
       "min     0.000000   0.017857   0.079365   0.071429   0.116883   0.190476   \n",
       "25%     0.897959   0.901786   0.904762   0.914286   0.922078   0.928571   \n",
       "50%     0.959184   0.946429   0.952381   0.957143   0.948052   0.952381   \n",
       "75%     0.979592   0.973214   0.976190   0.978571   0.974026   0.976190   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.976966  \n",
       "std     0.034972  \n",
       "min     0.813699  \n",
       "25%     0.982192  \n",
       "50%     0.986301  \n",
       "75%     0.989041  \n",
       "max     0.994521  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#80% pi coverage\n",
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-tbats_coverage_80.csv\n"
     ]
    }
   ],
   "source": [
    "#output 80% PI coverage\n",
    "metric = 'coverage_80'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting model... Time taken: 0.91767524878184\n",
      "cross-validation...\n",
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#90% PIs\n",
    "fitted_model = get_tbats_fitted(train[REGION])\n",
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "print('cross-validation...')\n",
    "#results with 80% CI\n",
    "results = time_series_cv(fitted_model,\n",
    "                         y_train=train[REGION], \n",
    "                         y_val=val[REGION], \n",
    "                         horizons=horizons, \n",
    "                         step=7,\n",
    "                         cl=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.977513</td>\n",
       "      <td>0.979894</td>\n",
       "      <td>0.982363</td>\n",
       "      <td>0.983371</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.985303</td>\n",
       "      <td>0.986243</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.995941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.056550</td>\n",
       "      <td>0.080064</td>\n",
       "      <td>0.062415</td>\n",
       "      <td>0.047657</td>\n",
       "      <td>0.038671</td>\n",
       "      <td>0.032748</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>0.024431</td>\n",
       "      <td>0.021979</td>\n",
       "      <td>0.019604</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>0.016000</td>\n",
       "      <td>0.003074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.877551</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.983562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.973214</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.994521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.987013</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.973545   0.968254   0.973545   0.977513   0.979894   0.982363   \n",
       "std     0.056550   0.080064   0.062415   0.047657   0.038671   0.032748   \n",
       "min     0.857143   0.642857   0.714286   0.785714   0.828571   0.857143   \n",
       "25%     1.000000   1.000000   0.976190   0.964286   0.971429   0.976190   \n",
       "50%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.983371   0.984127   0.985303   0.986243   0.987013   0.987654   \n",
       "std     0.027751   0.024431   0.021979   0.019604   0.017646   0.016000   \n",
       "min     0.877551   0.892857   0.904762   0.914286   0.922078   0.928571   \n",
       "25%     0.979592   0.973214   0.968254   0.971429   0.974026   0.976190   \n",
       "50%     1.000000   1.000000   1.000000   1.000000   0.987013   0.988095   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.995941  \n",
       "std     0.003074  \n",
       "min     0.983562  \n",
       "25%     0.994521  \n",
       "50%     0.997260  \n",
       "75%     0.997260  \n",
       "max     1.000000  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95% PIs\n",
    "cv_preds, cv_test, cv_intervals = results\n",
    "cv_coverage = prediction_int_coverage_cv(cv_actuals, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-tbats_coverage_95.csv\n"
     ]
    }
   ],
   "source": [
    "#output 95% PI coverage\n",
    "metric = 'coverage_95'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ambo",
   "language": "python",
   "name": "ambo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
