{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation: Facebook's Prophet\n",
    "---\n",
    "\n",
    "Facebook Prophet with New Year holiday.\n",
    "\n",
    "This notebook conducts cross validation of the method using a rolling forecast origin method.\n",
    "\n",
    "\n",
    "**The notebook outputs:**\n",
    "* MASE, RMSE and MAPE at 7 day intervals from 7 to 84 days and also a 365 day forecast.\n",
    "* 80 and 95% prediction intervals between 7 and 84 days and also 365 days.\n",
    "\n",
    "These are saved into the folder `results/model_selection/stage1/`\n",
    "\n",
    "---\n",
    "\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#error measures\n",
    "from forecast_tools.metrics import (mean_absolute_scaled_error, \n",
    "                                    root_mean_squared_error,\n",
    "                                    symmetric_mean_absolute_percentage_error)\n",
    "\n",
    "#models\n",
    "from fbprophet import Prophet\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to select exceptionally busy days as covariates.\n",
    "from amb_forecast.feature_engineering import (regular_busy_calender_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom ensemble class\n",
    "from amb_forecast.ensemble import (Ensemble, UnweightedVote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "The constants `TOP_LEVEL`, `STAGE`, `REGION`,`TRUST` and `METHOD` are used to control data selection and the directory for outputting results.  \n",
    "\n",
    "> Output file is `f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv'.csv`.  where metric will be smape, rmse, mase, coverage_80 and coverage_95. Note: `REGION`: is also used to select the correct data from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_LEVEL = '../../../results/model_selection'\n",
    "STAGE = 'temp'\n",
    "REGION = 'Trust'\n",
    "METHOD = 'fbp'\n",
    "\n",
    "FILE_NAME = 'Daily_Responses_5_Years_2019_full.csv'\n",
    "\n",
    "#split training and test data.\n",
    "TEST_SPLIT_DATE = '2019-01-01'\n",
    "\n",
    "#second subdivide: train and val\n",
    "VAL_SPLIT_DATE = '2017-07-01'\n",
    "\n",
    "#discard data after 2020 due to coronavirus\n",
    "#this is the subject of a seperate study.\n",
    "DISCARD_DATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in path\n",
    "path = f'../../../data/{FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_daily_data(path, index_col, by_col, \n",
    "                           values, dayfirst=False):\n",
    "    '''\n",
    "    Daily data is stored in long format.  Read in \n",
    "    and pivot to wide format so that there is a single \n",
    "    colmumn for each regions time series.\n",
    "    '''\n",
    "    df = pd.read_csv(path, index_col=index_col, parse_dates=True, dayfirst=dayfirst)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.index.rename(str(df.index.name).lower(), inplace=True)\n",
    "    \n",
    "    clean_table = pd.pivot_table(df, values=values.lower(), index=[index_col.lower()],\n",
    "                                 columns=[by_col.lower()], aggfunc=np.sum)\n",
    "    \n",
    "    clean_table.index.freq = 'D'\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  \n",
       "actual_dt                      \n",
       "2013-12-30  2042.0      255.0  \n",
       "2013-12-31  1996.0      260.0  \n",
       "2014-01-01  2570.0      351.0  \n",
       "2014-01-02  2013.0      258.0  \n",
       "2014-01-03  2056.0      269.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pre_process_daily_data(path, 'Actual_dt', 'ORA', 'Actual_Value', \n",
    "                               dayfirst=False)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Splot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ts_train_test_split(clean, split_date=TEST_SPLIT_DATE)\n",
    "\n",
    "#exclude data after 2020 due to coronavirus.\n",
    "test, discard = ts_train_test_split(test, split_date=DISCARD_DATE)\n",
    "\n",
    "#train split into train and validation\n",
    "train, val = ts_train_test_split(train, split_date=VAL_SPLIT_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 9)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#amount of training data\n",
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#amount of validation data\n",
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New years day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exceptional = regular_busy_calender_days(train[REGION], quantile=0.99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_year = pd.DataFrame({\n",
    "                         'holiday': 'new_year',\n",
    "                         'ds': pd.date_range(start=exceptional[0], \n",
    "                                             periods=20, \n",
    "                                             freq='YS')\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_year</td>\n",
       "      <td>2013-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>new_year</td>\n",
       "      <td>2014-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>new_year</td>\n",
       "      <td>2015-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>new_year</td>\n",
       "      <td>2016-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new_year</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    holiday         ds\n",
       "0  new_year 2013-01-01\n",
       "1  new_year 2014-01-01\n",
       "2  new_year 2015-01-01\n",
       "3  new_year 2016-01-01\n",
       "4  new_year 2017-01-01"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_year.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper classes for Prophet and statsmodels ARIMA\n",
    "\n",
    "Adapter/wrapper classes to enable usage within `Ensemble` class and work with cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FbProphetWrapper(object):\n",
    "    '''\n",
    "    Facade for FBProphet object - so that it can be\n",
    "    used within Ensemble with methods from other packages\n",
    "\n",
    "    '''\n",
    "    def __init__(self, training_index, holidays=None, interval_width=0.8,\n",
    "                 mcmc_samples=0, changepoint_prior_scale=0.05):\n",
    "        self._training_index = training_index\n",
    "        self._holidays = holidays\n",
    "        self._interval_width = interval_width\n",
    "        self._mcmc_samples = mcmc_samples\n",
    "        self._cp_prior_scale = changepoint_prior_scale\n",
    "\n",
    "    def _get_resids(self):\n",
    "        return self._train - self._forecast['yhat'][:-self._h]\n",
    "\n",
    "    def _get_preds(self):\n",
    "        return self._forecast['yhat'][:-self._h].to_numpy()\n",
    "\n",
    "    def fit(self, train):\n",
    "        \n",
    "        self._model = Prophet(holidays=self._holidays, \n",
    "                              interval_width=self._interval_width,\n",
    "                              mcmc_samples=self._mcmc_samples,\n",
    "                              changepoint_prior_scale=self._cp_prior_scale,\n",
    "                              daily_seasonality=False)\n",
    "        \n",
    "        \n",
    "        self._model.fit(self._pre_process_training(train))\n",
    "        self._t = len(train)\n",
    "        self._train = train\n",
    "        self.predict(len(train))\n",
    "\n",
    "    def _pre_process_training(self, train):\n",
    "\n",
    "        if len(train.shape) > 1:\n",
    "            y_train = train[:, 0]\n",
    "        else:\n",
    "            y_train = train\n",
    "\n",
    "        y_train = np.asarray(y_train)\n",
    "            \n",
    "        #extend the training index\n",
    "        if len(y_train) > len(self._training_index):\n",
    "            self._training_index = pd.date_range(start=self._training_index[0], \n",
    "                                                 periods=len(y_train),\n",
    "                                                 freq=self._training_index.freq)\n",
    "        \n",
    "        \n",
    "        prophet_train = pd.DataFrame(self._training_index)\n",
    "        prophet_train['y'] = y_train\n",
    "        prophet_train.columns = ['ds', 'y']\n",
    "        \n",
    "        return prophet_train\n",
    "\n",
    "    def predict(self, h, return_conf_int=False, alpha=0.2):\n",
    "        '''\n",
    "        forecast h steps ahead.\n",
    "        \n",
    "        Params:\n",
    "        ------\n",
    "        h: int\n",
    "            h-step forecast\n",
    "        \n",
    "        return_conf_int: bool, optional (default=False)\n",
    "            return 1 - alpha PI\n",
    "        \n",
    "        alpha: float, optional (default=0.2)\n",
    "            return 1 - alpha PI\n",
    "                       \n",
    "        Returns:\n",
    "        -------\n",
    "        np.array\n",
    "            If return_conf_int = False returns preds only\n",
    "            \n",
    "        np.array, np.array\n",
    "            If return_conf_int = True returns tuple of preds, pred_ints\n",
    "        '''\n",
    "        if isinstance(h, (np.ndarray, pd.DataFrame)):\n",
    "            h = len(h)\n",
    "        \n",
    "        self._h = h\n",
    "        future = self._model.make_future_dataframe(periods=h)\n",
    "        self._forecast = self._model.predict(future)\n",
    "\n",
    "        if return_conf_int:\n",
    "            return (self._forecast['yhat'][-h:].to_numpy(), \n",
    "                    self._forecast[['yhat_lower', 'yhat_upper']][-h:].to_numpy())\n",
    "        else:\n",
    "            return self._forecast['yhat'][-h:].to_numpy()\n",
    "            \n",
    "\n",
    "    fittedvalues = property(_get_preds)\n",
    "    resid = property(_get_resids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of fitting the model.\n",
    "1. FBProphet with new years day holiday.\n",
    "\n",
    "The code below demonstrates how to fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = FbProphetWrapper(training_index=train.index, \n",
    "                           holidays=new_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {'fbp': model_1}\n",
    "ens = Ensemble(estimators, UnweightedVote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit to training data in chosen region\n",
    "ens.fit(train[REGION])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict 7 days ahead\n",
    "H = 7\n",
    "ens_preds = ens.predict(horizon=H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2302.95867484, 2277.13777755, 2175.05797737, 2098.10556466,\n",
       "       2095.54782887, 2117.64655788, 2169.00810598])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view predictions\n",
    "ens_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with prediction intervals\n",
    "ens_preds, pi = ens.predict(horizon=H, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2302.95867484, 2277.13777755, 2175.05797737, 2098.10556466,\n",
       "       2095.54782887, 2117.64655788, 2169.00810598])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2205.28672538, 2406.02440461],\n",
       "       [2173.04947732, 2378.19927565],\n",
       "       [2072.19469448, 2275.5084746 ],\n",
       "       [1988.88965749, 2203.49027235],\n",
       "       [1985.19651326, 2199.09451664],\n",
       "       [2013.87671931, 2217.93287629],\n",
       "       [2069.86554857, 2262.46745335]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation functions\n",
    "\n",
    "`time_series_cv` implements rolling forecast origin cross validation for time series.  \n",
    "It does not calculate forecast error, but instead returns the predictions, pred intervals and actuals in an array that can be passed to any forecast error function. (this is for efficiency and allows additional metrics to be calculated if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(model, train, val, horizons, alpha=0.2, step=1):\n",
    "    '''\n",
    "    Time series cross validation across multiple horizons for a single model.\n",
    "\n",
    "    Incrementally adds additional training data to the model and tests\n",
    "    across a provided list of forecast horizons. Note that function tests a\n",
    "    model only against complete validation sets.  E.g. if horizon = 15 and \n",
    "    len(val) = 12 then no testing is done.  In the case of multiple horizons\n",
    "    e.g. [7, 14, 28] then the function will use the maximum forecast horizon\n",
    "    to calculate the number of iterations i.e if len(val) = 365 and step = 1\n",
    "    then no. iterations = len(val) - max(horizon) = 365 - 28 = 337.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    model - forecasting model\n",
    "\n",
    "    train - np.array - vector of training data\n",
    "\n",
    "    val - np.array - vector of validation data\n",
    "\n",
    "    horizon - list of ints, forecast horizon e.g. [7, 14, 28] days\n",
    "    \n",
    "    alpha - float, optional (default=0.2)\n",
    "        1 - alpha prediction interval specification\n",
    "\n",
    "    step -- int, optional (default=1)\n",
    "            step taken in cross validation \n",
    "            e.g. 1 in next cross validation training data includes next point \n",
    "            from the validation set.\n",
    "            e.g. 7 in the next cross validation training data includes next 7 points\n",
    "            (default=1)\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    np.array, np.array, np.array\n",
    "        - cv_preds, cv_test, cv_intervals\n",
    "    '''\n",
    "    \n",
    "    #point forecasts\n",
    "    cv_preds = [] \n",
    "    #ground truth observations\n",
    "    cv_actuals = [] \n",
    "    #prediction intervals\n",
    "    cv_pis = []\n",
    "    \n",
    "    split = 0\n",
    "\n",
    "    print('split => ', end=\"\")\n",
    "    for i in range(0, len(val) - max(horizons) + 1, step):\n",
    "        split += 1\n",
    "        print(f'{split}, ', end=\"\")\n",
    "                \n",
    "        train_cv = np.concatenate([train, val[:i]], axis=0)\n",
    "        model.fit(train_cv)\n",
    "        \n",
    "        #predict the maximum horizon \n",
    "        preds, pis = model.predict(horizon=len(val[i:i+max(horizons)]), \n",
    "                                   return_conf_int=True,\n",
    "                                   alpha=alpha)        \n",
    "        cv_h_preds = []\n",
    "        cv_test = []\n",
    "        cv_h_pis = []\n",
    "        \n",
    "        #sub horizon calculations\n",
    "        for h in horizons:\n",
    "            #store the h-step prediction\n",
    "            cv_h_preds.append(preds[:h])\n",
    "            #store the h-step actual value\n",
    "            cv_test.append(val.iloc[i:i+h])    \n",
    "            cv_h_pis.append(pis[:h])\n",
    "                     \n",
    "        cv_preds.append(cv_h_preds)\n",
    "        cv_actuals.append(cv_test)\n",
    "        cv_pis.append(cv_h_pis)\n",
    "        \n",
    "    print('done.\\n')        \n",
    "    return cv_preds, cv_actuals, cv_pis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for calculating CV scores for point predictions and coverage.\n",
    "\n",
    "These functions have been written to work with the output of `time_series_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast error in the current split\n",
    "    \n",
    "    Params:\n",
    "    -----\n",
    "    cv_preds, np.array\n",
    "        Split predictions\n",
    "        \n",
    "    \n",
    "    cv_test: np.array\n",
    "        acutal ground truth observations\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        np.ndarray\n",
    "            cross validation errors for split\n",
    "    '''\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = error_func(cv_test[split], cv_preds[split])\n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast errors by forecast horizon\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    cv_preds: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    cv_test: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        \n",
    "    '''\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error(cv_preds[h], cv_test[h], error_func)\n",
    "        horizon_errors.append(split_errors)\n",
    "\n",
    "    return np.array(horizon_errors)\n",
    "\n",
    "def split_coverage(cv_test, cv_intervals):\n",
    "    n_splits = len(cv_test)\n",
    "    cv_errors = []\n",
    "        \n",
    "    for split in range(n_splits):\n",
    "        val = np.asarray(cv_test[split])\n",
    "        lower = cv_intervals[split].T[0]\n",
    "        upper = cv_intervals[split].T[1]\n",
    "        \n",
    "        coverage = len(np.where((val > lower) & (val < upper))[0])\n",
    "        coverage = coverage / len(val)\n",
    "        \n",
    "        cv_errors.append(coverage)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "    \n",
    "    \n",
    "def prediction_int_coverage_cv(cv_test, cv_intervals):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_intervals = np.array(cv_intervals)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_coverage = []\n",
    "    for h in range(n_horizons):\n",
    "        split_coverages = split_coverage(cv_test[h], cv_intervals[h])\n",
    "        horizon_coverage.append(split_coverages)\n",
    "\n",
    "    return np.array(horizon_coverage)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error_scaled(cv_preds, cv_test, y_train):\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = mean_absolute_scaled_error(cv_test[split], cv_preds[split], \n",
    "                                                y_train, period=7)\n",
    "        \n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv_scaled(cv_preds, cv_test, y_train):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error_scaled(cv_preds[h], cv_test[h], y_train)\n",
    "        horizon_errors.append(split_errors)\n",
    "        \n",
    "    return np.array(horizon_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ensemble(meta_learner=None, fb_interval=0.8):\n",
    "    '''\n",
    "    Create ensemble model\n",
    "    '''\n",
    "    if meta_learner is None:\n",
    "        meta_learner = UnweightedVote()\n",
    "        \n",
    "    model_1 = FbProphetWrapper(training_index=train.index, \n",
    "                           holidays=new_year, interval_width=fb_interval)\n",
    "    \n",
    "    estimators = {'fbp': model_1}\n",
    "    return Ensemble(estimators, UnweightedVote())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run cross validation\n",
    "\n",
    "This is run twices once each for 80 and 95% prediction intervals.  The 2nd run is required due to the way Prophet generates prediction intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "model = get_ensemble()\n",
    "\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.2, step=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# symmetric MAPE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.992764</td>\n",
       "      <td>3.054805</td>\n",
       "      <td>3.077355</td>\n",
       "      <td>3.085396</td>\n",
       "      <td>3.098144</td>\n",
       "      <td>3.115493</td>\n",
       "      <td>3.138307</td>\n",
       "      <td>3.163085</td>\n",
       "      <td>3.191124</td>\n",
       "      <td>3.216202</td>\n",
       "      <td>3.247082</td>\n",
       "      <td>3.294733</td>\n",
       "      <td>4.231241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.453381</td>\n",
       "      <td>1.252905</td>\n",
       "      <td>1.008357</td>\n",
       "      <td>0.817484</td>\n",
       "      <td>0.727439</td>\n",
       "      <td>0.678602</td>\n",
       "      <td>0.630983</td>\n",
       "      <td>0.580087</td>\n",
       "      <td>0.543042</td>\n",
       "      <td>0.526889</td>\n",
       "      <td>0.518761</td>\n",
       "      <td>0.513413</td>\n",
       "      <td>0.710843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.823558</td>\n",
       "      <td>1.216192</td>\n",
       "      <td>1.233591</td>\n",
       "      <td>1.474079</td>\n",
       "      <td>1.760108</td>\n",
       "      <td>1.755597</td>\n",
       "      <td>1.805950</td>\n",
       "      <td>2.047982</td>\n",
       "      <td>2.154263</td>\n",
       "      <td>2.417840</td>\n",
       "      <td>2.476300</td>\n",
       "      <td>2.480856</td>\n",
       "      <td>2.972044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.805585</td>\n",
       "      <td>2.155122</td>\n",
       "      <td>2.346848</td>\n",
       "      <td>2.504084</td>\n",
       "      <td>2.706935</td>\n",
       "      <td>2.712459</td>\n",
       "      <td>2.782993</td>\n",
       "      <td>2.880657</td>\n",
       "      <td>2.844870</td>\n",
       "      <td>2.874326</td>\n",
       "      <td>2.838934</td>\n",
       "      <td>2.820658</td>\n",
       "      <td>3.810998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.634136</td>\n",
       "      <td>3.009083</td>\n",
       "      <td>2.946270</td>\n",
       "      <td>3.060609</td>\n",
       "      <td>3.132027</td>\n",
       "      <td>3.191006</td>\n",
       "      <td>3.149871</td>\n",
       "      <td>3.124042</td>\n",
       "      <td>3.176737</td>\n",
       "      <td>3.132216</td>\n",
       "      <td>3.094246</td>\n",
       "      <td>3.162486</td>\n",
       "      <td>4.274855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.803801</td>\n",
       "      <td>3.706259</td>\n",
       "      <td>3.562549</td>\n",
       "      <td>3.657160</td>\n",
       "      <td>3.651882</td>\n",
       "      <td>3.547876</td>\n",
       "      <td>3.451511</td>\n",
       "      <td>3.592388</td>\n",
       "      <td>3.719088</td>\n",
       "      <td>3.645970</td>\n",
       "      <td>3.650612</td>\n",
       "      <td>3.761396</td>\n",
       "      <td>4.652082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.008097</td>\n",
       "      <td>5.879231</td>\n",
       "      <td>5.047494</td>\n",
       "      <td>4.396623</td>\n",
       "      <td>4.217112</td>\n",
       "      <td>4.225105</td>\n",
       "      <td>4.310605</td>\n",
       "      <td>4.214964</td>\n",
       "      <td>4.095931</td>\n",
       "      <td>4.121370</td>\n",
       "      <td>4.171102</td>\n",
       "      <td>4.192921</td>\n",
       "      <td>5.980493</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    2.992764   3.054805   3.077355   3.085396   3.098144   3.115493   \n",
       "std     1.453381   1.252905   1.008357   0.817484   0.727439   0.678602   \n",
       "min     0.823558   1.216192   1.233591   1.474079   1.760108   1.755597   \n",
       "25%     1.805585   2.155122   2.346848   2.504084   2.706935   2.712459   \n",
       "50%     2.634136   3.009083   2.946270   3.060609   3.132027   3.191006   \n",
       "75%     3.803801   3.706259   3.562549   3.657160   3.651882   3.547876   \n",
       "max     7.008097   5.879231   5.047494   4.396623   4.217112   4.225105   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    3.138307   3.163085   3.191124   3.216202   3.247082   3.294733   \n",
       "std     0.630983   0.580087   0.543042   0.526889   0.518761   0.513413   \n",
       "min     1.805950   2.047982   2.154263   2.417840   2.476300   2.480856   \n",
       "25%     2.782993   2.880657   2.844870   2.874326   2.838934   2.820658   \n",
       "50%     3.149871   3.124042   3.176737   3.132216   3.094246   3.162486   \n",
       "75%     3.451511   3.592388   3.719088   3.645970   3.650612   3.761396   \n",
       "max     4.310605   4.214964   4.095931   4.121370   4.171102   4.192921   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    4.231241  \n",
       "std     0.710843  \n",
       "min     2.972044  \n",
       "25%     3.810998  \n",
       "50%     4.274855  \n",
       "75%     4.652082  \n",
       "max     5.980493  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_preds, cv_test, cv_intervals = results\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, \n",
    "                               symmetric_mean_absolute_percentage_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/temp/Trust-fbp_smape.csv\n"
     ]
    }
   ],
   "source": [
    "#output sMAPE results to file\n",
    "metric = 'smape'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSE results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>81.477287</td>\n",
       "      <td>86.065006</td>\n",
       "      <td>88.932570</td>\n",
       "      <td>90.760518</td>\n",
       "      <td>92.251442</td>\n",
       "      <td>93.563846</td>\n",
       "      <td>94.933570</td>\n",
       "      <td>96.359590</td>\n",
       "      <td>97.673905</td>\n",
       "      <td>98.775720</td>\n",
       "      <td>99.894313</td>\n",
       "      <td>101.424357</td>\n",
       "      <td>121.644895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>45.993262</td>\n",
       "      <td>41.350955</td>\n",
       "      <td>36.300717</td>\n",
       "      <td>32.138012</td>\n",
       "      <td>28.970328</td>\n",
       "      <td>26.261380</td>\n",
       "      <td>23.533562</td>\n",
       "      <td>20.534614</td>\n",
       "      <td>17.567544</td>\n",
       "      <td>15.222167</td>\n",
       "      <td>12.902539</td>\n",
       "      <td>10.740993</td>\n",
       "      <td>16.664464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>22.028363</td>\n",
       "      <td>40.772142</td>\n",
       "      <td>38.686507</td>\n",
       "      <td>45.753424</td>\n",
       "      <td>50.326890</td>\n",
       "      <td>49.693287</td>\n",
       "      <td>50.908165</td>\n",
       "      <td>57.920570</td>\n",
       "      <td>59.550988</td>\n",
       "      <td>66.307828</td>\n",
       "      <td>67.704705</td>\n",
       "      <td>67.918715</td>\n",
       "      <td>92.635860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>54.607258</td>\n",
       "      <td>61.252855</td>\n",
       "      <td>65.851423</td>\n",
       "      <td>69.485072</td>\n",
       "      <td>73.950025</td>\n",
       "      <td>74.086058</td>\n",
       "      <td>76.590836</td>\n",
       "      <td>79.519301</td>\n",
       "      <td>84.839158</td>\n",
       "      <td>88.273722</td>\n",
       "      <td>95.455559</td>\n",
       "      <td>98.022181</td>\n",
       "      <td>112.803903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>69.845118</td>\n",
       "      <td>79.166901</td>\n",
       "      <td>81.663500</td>\n",
       "      <td>87.585046</td>\n",
       "      <td>83.961145</td>\n",
       "      <td>82.138745</td>\n",
       "      <td>94.865665</td>\n",
       "      <td>105.240232</td>\n",
       "      <td>103.843003</td>\n",
       "      <td>107.512793</td>\n",
       "      <td>105.805463</td>\n",
       "      <td>104.099944</td>\n",
       "      <td>122.390253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>93.257754</td>\n",
       "      <td>96.850014</td>\n",
       "      <td>94.645084</td>\n",
       "      <td>106.146969</td>\n",
       "      <td>109.704715</td>\n",
       "      <td>113.304334</td>\n",
       "      <td>115.900079</td>\n",
       "      <td>115.098938</td>\n",
       "      <td>112.113194</td>\n",
       "      <td>110.231165</td>\n",
       "      <td>108.443285</td>\n",
       "      <td>108.361383</td>\n",
       "      <td>130.932972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>258.759134</td>\n",
       "      <td>214.484114</td>\n",
       "      <td>179.703312</td>\n",
       "      <td>161.309311</td>\n",
       "      <td>147.268953</td>\n",
       "      <td>136.451304</td>\n",
       "      <td>127.909123</td>\n",
       "      <td>121.840427</td>\n",
       "      <td>117.505871</td>\n",
       "      <td>113.562275</td>\n",
       "      <td>115.017211</td>\n",
       "      <td>113.273749</td>\n",
       "      <td>164.628060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              7           14          21          28          35          42   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    81.477287   86.065006   88.932570   90.760518   92.251442   93.563846   \n",
       "std     45.993262   41.350955   36.300717   32.138012   28.970328   26.261380   \n",
       "min     22.028363   40.772142   38.686507   45.753424   50.326890   49.693287   \n",
       "25%     54.607258   61.252855   65.851423   69.485072   73.950025   74.086058   \n",
       "50%     69.845118   79.166901   81.663500   87.585046   83.961145   82.138745   \n",
       "75%     93.257754   96.850014   94.645084  106.146969  109.704715  113.304334   \n",
       "max    258.759134  214.484114  179.703312  161.309311  147.268953  136.451304   \n",
       "\n",
       "              49          56          63          70          77          84   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    94.933570   96.359590   97.673905   98.775720   99.894313  101.424357   \n",
       "std     23.533562   20.534614   17.567544   15.222167   12.902539   10.740993   \n",
       "min     50.908165   57.920570   59.550988   66.307828   67.704705   67.918715   \n",
       "25%     76.590836   79.519301   84.839158   88.273722   95.455559   98.022181   \n",
       "50%     94.865665  105.240232  103.843003  107.512793  105.805463  104.099944   \n",
       "75%    115.900079  115.098938  112.113194  110.231165  108.443285  108.361383   \n",
       "max    127.909123  121.840427  117.505871  113.562275  115.017211  113.273749   \n",
       "\n",
       "              365  \n",
       "count   27.000000  \n",
       "mean   121.644895  \n",
       "std     16.664464  \n",
       "min     92.635860  \n",
       "25%    112.803903  \n",
       "50%    122.390253  \n",
       "75%    130.932972  \n",
       "max    164.628060  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_preds, cv_test, cv_intervals = results\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, root_mean_squared_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/temp/Trust-fbp_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "#output RMSE to file\n",
    "metric = 'rmse'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Absolute Scaled Error (MASE)\n",
    "\n",
    "Scaled by one-step insample Seasonal Naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.807967</td>\n",
       "      <td>0.824645</td>\n",
       "      <td>0.830861</td>\n",
       "      <td>0.833448</td>\n",
       "      <td>0.837451</td>\n",
       "      <td>0.842769</td>\n",
       "      <td>0.849555</td>\n",
       "      <td>0.856983</td>\n",
       "      <td>0.865372</td>\n",
       "      <td>0.873086</td>\n",
       "      <td>0.882331</td>\n",
       "      <td>0.896192</td>\n",
       "      <td>1.148302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.423243</td>\n",
       "      <td>0.360452</td>\n",
       "      <td>0.288207</td>\n",
       "      <td>0.231103</td>\n",
       "      <td>0.201529</td>\n",
       "      <td>0.182511</td>\n",
       "      <td>0.164352</td>\n",
       "      <td>0.145062</td>\n",
       "      <td>0.130012</td>\n",
       "      <td>0.122297</td>\n",
       "      <td>0.116913</td>\n",
       "      <td>0.113685</td>\n",
       "      <td>0.196648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.234997</td>\n",
       "      <td>0.344559</td>\n",
       "      <td>0.348230</td>\n",
       "      <td>0.416005</td>\n",
       "      <td>0.487381</td>\n",
       "      <td>0.483703</td>\n",
       "      <td>0.499805</td>\n",
       "      <td>0.562564</td>\n",
       "      <td>0.589535</td>\n",
       "      <td>0.661236</td>\n",
       "      <td>0.675048</td>\n",
       "      <td>0.675430</td>\n",
       "      <td>0.809650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.488794</td>\n",
       "      <td>0.590129</td>\n",
       "      <td>0.632499</td>\n",
       "      <td>0.674166</td>\n",
       "      <td>0.725870</td>\n",
       "      <td>0.726999</td>\n",
       "      <td>0.729204</td>\n",
       "      <td>0.766759</td>\n",
       "      <td>0.805450</td>\n",
       "      <td>0.809345</td>\n",
       "      <td>0.806517</td>\n",
       "      <td>0.803910</td>\n",
       "      <td>1.034837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.703273</td>\n",
       "      <td>0.786611</td>\n",
       "      <td>0.754741</td>\n",
       "      <td>0.789199</td>\n",
       "      <td>0.801155</td>\n",
       "      <td>0.848755</td>\n",
       "      <td>0.852255</td>\n",
       "      <td>0.851214</td>\n",
       "      <td>0.860420</td>\n",
       "      <td>0.846333</td>\n",
       "      <td>0.860574</td>\n",
       "      <td>0.892673</td>\n",
       "      <td>1.152226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.977523</td>\n",
       "      <td>0.973144</td>\n",
       "      <td>0.926313</td>\n",
       "      <td>1.009757</td>\n",
       "      <td>0.992046</td>\n",
       "      <td>0.989316</td>\n",
       "      <td>0.982963</td>\n",
       "      <td>0.974243</td>\n",
       "      <td>0.963264</td>\n",
       "      <td>0.945713</td>\n",
       "      <td>0.955735</td>\n",
       "      <td>0.988183</td>\n",
       "      <td>1.256168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.172972</td>\n",
       "      <td>1.782926</td>\n",
       "      <td>1.439076</td>\n",
       "      <td>1.291793</td>\n",
       "      <td>1.167713</td>\n",
       "      <td>1.116409</td>\n",
       "      <td>1.137327</td>\n",
       "      <td>1.113348</td>\n",
       "      <td>1.080469</td>\n",
       "      <td>1.086529</td>\n",
       "      <td>1.104837</td>\n",
       "      <td>1.112750</td>\n",
       "      <td>1.655542</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.807967   0.824645   0.830861   0.833448   0.837451   0.842769   \n",
       "std     0.423243   0.360452   0.288207   0.231103   0.201529   0.182511   \n",
       "min     0.234997   0.344559   0.348230   0.416005   0.487381   0.483703   \n",
       "25%     0.488794   0.590129   0.632499   0.674166   0.725870   0.726999   \n",
       "50%     0.703273   0.786611   0.754741   0.789199   0.801155   0.848755   \n",
       "75%     0.977523   0.973144   0.926313   1.009757   0.992046   0.989316   \n",
       "max     2.172972   1.782926   1.439076   1.291793   1.167713   1.116409   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.849555   0.856983   0.865372   0.873086   0.882331   0.896192   \n",
       "std     0.164352   0.145062   0.130012   0.122297   0.116913   0.113685   \n",
       "min     0.499805   0.562564   0.589535   0.661236   0.675048   0.675430   \n",
       "25%     0.729204   0.766759   0.805450   0.809345   0.806517   0.803910   \n",
       "50%     0.852255   0.851214   0.860420   0.846333   0.860574   0.892673   \n",
       "75%     0.982963   0.974243   0.963264   0.945713   0.955735   0.988183   \n",
       "max     1.137327   1.113348   1.080469   1.086529   1.104837   1.112750   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    1.148302  \n",
       "std     0.196648  \n",
       "min     0.809650  \n",
       "25%     1.034837  \n",
       "50%     1.152226  \n",
       "75%     1.256168  \n",
       "max     1.655542  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_errors = forecast_errors_cv_scaled(cv_preds, cv_test, train[REGION])\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/temp/Trust-fbp_mase.csv\n"
     ]
    }
   ],
   "source": [
    "#output mase to file.\n",
    "metric = 'mase'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 80% Prediction Interval Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.769841</td>\n",
       "      <td>0.763668</td>\n",
       "      <td>0.763228</td>\n",
       "      <td>0.765079</td>\n",
       "      <td>0.763668</td>\n",
       "      <td>0.764928</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.760141</td>\n",
       "      <td>0.757672</td>\n",
       "      <td>0.752766</td>\n",
       "      <td>0.745591</td>\n",
       "      <td>0.669305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.203321</td>\n",
       "      <td>0.170802</td>\n",
       "      <td>0.140693</td>\n",
       "      <td>0.117264</td>\n",
       "      <td>0.107002</td>\n",
       "      <td>0.102073</td>\n",
       "      <td>0.098424</td>\n",
       "      <td>0.095138</td>\n",
       "      <td>0.092590</td>\n",
       "      <td>0.091429</td>\n",
       "      <td>0.092078</td>\n",
       "      <td>0.091391</td>\n",
       "      <td>0.100698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.542857</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.589286</td>\n",
       "      <td>0.587302</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.597403</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.430137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.726190</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.668831</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.601370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.779221</td>\n",
       "      <td>0.773810</td>\n",
       "      <td>0.665753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.816327</td>\n",
       "      <td>0.821429</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.815476</td>\n",
       "      <td>0.720548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.883117</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.841096</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.777778   0.769841   0.763668   0.763228   0.765079   0.763668   \n",
       "std     0.203321   0.170802   0.140693   0.117264   0.107002   0.102073   \n",
       "min     0.285714   0.285714   0.380952   0.500000   0.542857   0.547619   \n",
       "25%     0.642857   0.678571   0.666667   0.714286   0.714286   0.726190   \n",
       "50%     0.857143   0.785714   0.761905   0.750000   0.771429   0.785714   \n",
       "75%     0.928571   0.892857   0.857143   0.857143   0.842857   0.809524   \n",
       "max     1.000000   1.000000   0.952381   0.964286   0.914286   0.928571   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.764928   0.761905   0.760141   0.757672   0.752766   0.745591   \n",
       "std     0.098424   0.095138   0.092590   0.091429   0.092078   0.091391   \n",
       "min     0.571429   0.589286   0.587302   0.600000   0.597403   0.583333   \n",
       "25%     0.724490   0.687500   0.666667   0.685714   0.668831   0.666667   \n",
       "50%     0.795918   0.785714   0.761905   0.785714   0.779221   0.773810   \n",
       "75%     0.816327   0.821429   0.833333   0.828571   0.831169   0.815476   \n",
       "max     0.938776   0.910714   0.920635   0.871429   0.883117   0.892857   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.669305  \n",
       "std     0.100698  \n",
       "min     0.430137  \n",
       "25%     0.601370  \n",
       "50%     0.665753  \n",
       "75%     0.720548  \n",
       "max     0.841096  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#80% PIs\n",
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/temp/Trust-fbp_coverage_80.csv\n"
     ]
    }
   ],
   "source": [
    "#write 80% coverage to file\n",
    "metric = 'coverage_80'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 95% Prediction Interval Coverage\n",
    "\n",
    "Rerun analysis and obtain 95% Prediction intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "model = get_ensemble(fb_interval=0.95)\n",
    "\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.05, step=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.915344</td>\n",
       "      <td>0.912698</td>\n",
       "      <td>0.913580</td>\n",
       "      <td>0.914021</td>\n",
       "      <td>0.913228</td>\n",
       "      <td>0.910935</td>\n",
       "      <td>0.908541</td>\n",
       "      <td>0.906746</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.902116</td>\n",
       "      <td>0.900914</td>\n",
       "      <td>0.898589</td>\n",
       "      <td>0.880670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.138727</td>\n",
       "      <td>0.114377</td>\n",
       "      <td>0.092485</td>\n",
       "      <td>0.078158</td>\n",
       "      <td>0.071530</td>\n",
       "      <td>0.067857</td>\n",
       "      <td>0.064131</td>\n",
       "      <td>0.059294</td>\n",
       "      <td>0.056206</td>\n",
       "      <td>0.054428</td>\n",
       "      <td>0.053078</td>\n",
       "      <td>0.049347</td>\n",
       "      <td>0.047873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.771429</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.793651</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.792208</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.742466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.839286</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.887755</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.841270</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.849315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.910714</td>\n",
       "      <td>0.920635</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.922078</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.882192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.959184</td>\n",
       "      <td>0.955357</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.940476</td>\n",
       "      <td>0.916438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.953425</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.915344   0.912698   0.913580   0.914021   0.913228   0.910935   \n",
       "std     0.138727   0.114377   0.092485   0.078158   0.071530   0.067857   \n",
       "min     0.428571   0.571429   0.714286   0.750000   0.771429   0.761905   \n",
       "25%     0.857143   0.892857   0.880952   0.839286   0.857143   0.880952   \n",
       "50%     1.000000   0.928571   0.952381   0.928571   0.942857   0.928571   \n",
       "75%     1.000000   1.000000   1.000000   0.964286   0.971429   0.952381   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.908541   0.906746   0.904762   0.902116   0.900914   0.898589   \n",
       "std     0.064131   0.059294   0.056206   0.054428   0.053078   0.049347   \n",
       "min     0.795918   0.803571   0.793651   0.785714   0.792208   0.797619   \n",
       "25%     0.887755   0.857143   0.841270   0.857143   0.863636   0.857143   \n",
       "50%     0.897959   0.910714   0.920635   0.914286   0.922078   0.916667   \n",
       "75%     0.959184   0.955357   0.944444   0.928571   0.935065   0.940476   \n",
       "max     1.000000   0.982143   0.984127   0.971429   0.974026   0.976190   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.880670  \n",
       "std     0.047873  \n",
       "min     0.742466  \n",
       "25%     0.849315  \n",
       "50%     0.882192  \n",
       "75%     0.916438  \n",
       "max     0.953425  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95% PIs\n",
    "cv_preds, cv_test, cv_intervals = results\n",
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/temp/Trust-fbp_coverage_95.csv\n"
     ]
    }
   ],
   "source": [
    "#write 95% coverage to file\n",
    "metric = 'coverage_95'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
