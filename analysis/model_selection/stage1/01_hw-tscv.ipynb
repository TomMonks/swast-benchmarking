{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Cross Validation: Holt-Winters Exponential Smoothing with additive errors and seasonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "#forecast error metrics\n",
    "from forecast_tools.metrics import (mean_absolute_scaled_error, \n",
    "                                    root_mean_squared_error,\n",
    "                                    symmetric_mean_absolute_percentage_error)\n",
    "\n",
    "import statsmodels as sm\n",
    "from statsmodels.tsa.statespace.exponential_smoothing import ExponentialSmoothing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11.0\n"
     ]
    }
   ],
   "source": [
    "print(sm.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ensemble learning\n",
    "from amb_forecast.ensemble import (Ensemble, UnweightedVote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Input\n",
    "\n",
    "The constants `TOP_LEVEL`, `STAGE`, `REGION`,`TRUST` and `METHOD` are used to control data selection and the directory for outputting results.  \n",
    "\n",
    "> Output file is `f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv'.csv`.  where metric will be smape, rmse, mase, coverage_80 and coverage_95. Note: `REGION`: is also used to select the correct data from the input dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_LEVEL = '../../../results/model_selection'\n",
    "STAGE = 'stage1'\n",
    "REGION = 'Trust'\n",
    "METHOD = 'hw'\n",
    "\n",
    "FILE_NAME = 'Daily_Responses_5_Years_2019_full.csv'\n",
    "\n",
    "#split training and test data.\n",
    "TEST_SPLIT_DATE = '2019-01-01'\n",
    "\n",
    "#second subdivide: train and val\n",
    "VAL_SPLIT_DATE = '2017-07-01'\n",
    "\n",
    "#discard data after 2020 due to coronavirus\n",
    "#this is the subject of a seperate study.\n",
    "DISCARD_DATE = '2020-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in path\n",
    "path = f'../../../data/{FILE_NAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_daily_data(path, index_col, by_col, \n",
    "                           values, dayfirst=False):\n",
    "    '''\n",
    "    Daily data is stored in long format.  Read in \n",
    "    and pivot to wide format so that there is a single \n",
    "    colmumn for each regions time series.\n",
    "    '''\n",
    "    df = pd.read_csv(path, index_col=index_col, parse_dates=True, \n",
    "                     dayfirst=dayfirst)\n",
    "    df.columns = map(str.lower, df.columns)\n",
    "    df.index.rename(str(df.index.name).lower(), inplace=True)\n",
    "    \n",
    "    clean_table = pd.pivot_table(df, values=values.lower(), \n",
    "                                 index=[index_col.lower()],\n",
    "                                 columns=[by_col.lower()], aggfunc=np.sum)\n",
    "    \n",
    "    clean_table.index.freq = 'D'\n",
    "    \n",
    "    return clean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ora</th>\n",
       "      <th>BNSSG</th>\n",
       "      <th>Cornwall</th>\n",
       "      <th>Devon</th>\n",
       "      <th>Dorset</th>\n",
       "      <th>Gloucestershire</th>\n",
       "      <th>OOA</th>\n",
       "      <th>Somerset</th>\n",
       "      <th>Trust</th>\n",
       "      <th>Wiltshire</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-12-30</th>\n",
       "      <td>415.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>502.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>2042.0</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-12-31</th>\n",
       "      <td>420.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>302.0</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.0</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01</th>\n",
       "      <td>549.0</td>\n",
       "      <td>341.0</td>\n",
       "      <td>566.0</td>\n",
       "      <td>392.0</td>\n",
       "      <td>157.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>213.0</td>\n",
       "      <td>2570.0</td>\n",
       "      <td>351.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>450.0</td>\n",
       "      <td>218.0</td>\n",
       "      <td>499.0</td>\n",
       "      <td>301.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167.0</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>258.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>419.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>503.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>195.0</td>\n",
       "      <td>2056.0</td>\n",
       "      <td>269.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "ora         BNSSG  Cornwall  Devon  Dorset  Gloucestershire  OOA  Somerset  \\\n",
       "actual_dt                                                                    \n",
       "2013-12-30  415.0     220.0  502.0   336.0            129.0  NaN     183.0   \n",
       "2013-12-31  420.0     236.0  468.0   302.0            128.0  NaN     180.0   \n",
       "2014-01-01  549.0     341.0  566.0   392.0            157.0  NaN     213.0   \n",
       "2014-01-02  450.0     218.0  499.0   301.0            115.0  NaN     167.0   \n",
       "2014-01-03  419.0     229.0  503.0   304.0            135.0  NaN     195.0   \n",
       "\n",
       "ora          Trust  Wiltshire  \n",
       "actual_dt                      \n",
       "2013-12-30  2042.0      255.0  \n",
       "2013-12-31  1996.0      260.0  \n",
       "2014-01-01  2570.0      351.0  \n",
       "2014-01-02  2013.0      258.0  \n",
       "2014-01-03  2056.0      269.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean = pre_process_daily_data(path, 'Actual_dt', 'ORA', 'Actual_Value', \n",
    "                               dayfirst=False)\n",
    "clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_train_test_split(data, split_date):\n",
    "    '''\n",
    "    Split time series into training and test data\n",
    "    \n",
    "    Parameters:\n",
    "    -------\n",
    "    data - pd.DataFrame - time series data.  Index expected as datatimeindex\n",
    "    split_date - the date on which to split the time series\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple (len=2) \n",
    "    0. pandas.DataFrame - training dataset\n",
    "    1. pandas.DataFrame - test dataset\n",
    "    '''\n",
    "    train = data.loc[data.index < split_date]\n",
    "    test = data.loc[data.index >= split_date]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ts_train_test_split(clean, split_date=TEST_SPLIT_DATE)\n",
    "\n",
    "#exclude data after 2020 due to coronavirus.\n",
    "test, discard = ts_train_test_split(test, split_date=DISCARD_DATE)\n",
    "\n",
    "#train split into train and validation\n",
    "train, val = ts_train_test_split(train, split_date=VAL_SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1279, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(549, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Test fitting and predicting with model.\n",
    "\n",
    "The class below is a 'wrapper' class that provides the same interfacew for all methods and works in the time series cross valiation code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialSmoothingWrapper:\n",
    "    '''\n",
    "    Facade for statsmodels exponential smoothing models.  This wrapper\n",
    "    provides a common interface for all models and allow interop with\n",
    "    the custom time series cross validation code.\n",
    "    '''\n",
    "    def __init__(self, trend=False, damped_trend=False, seasonal=None):\n",
    "        self._trend = trend\n",
    "        self._seasonal= seasonal\n",
    "        self._damped_trend = damped_trend\n",
    "\n",
    "    def _get_resids(self):\n",
    "        return self._fitted.resid\n",
    "\n",
    "    def _get_preds(self):\n",
    "        return self._fitted.fittedvalues\n",
    "\n",
    "    def fit(self, train):\n",
    "        '''\n",
    "        Fit the model\n",
    "        \n",
    "        Parameters:\n",
    "        train: array-like\n",
    "            time series to fit.\n",
    "        '''\n",
    "        self._model = ExponentialSmoothing(endog=train,\n",
    "                                          trend=self._trend, \n",
    "                                          damped_trend=self._damped_trend,\n",
    "                                          seasonal=self._seasonal)\n",
    "        self._fitted = self._model.fit()\n",
    "        self._t = len(train)\n",
    "    \n",
    "    def predict(self, horizon, return_conf_int=False, alpha=0.2):\n",
    "        '''\n",
    "        Forecast the time series from the final point in the fitted series.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        \n",
    "        horizon: int\n",
    "            steps ahead to forecast \n",
    "            \n",
    "        return_conf_int: bool, optional (default=False)\n",
    "            Return prediction interval?  \n",
    "            \n",
    "        alpha: float\n",
    "            Used if return_conf_int=True. 100(1-alpha) interval.\n",
    "        '''\n",
    "        \n",
    "        forecast = self._fitted.get_forecast(horizon)\n",
    "        \n",
    "        mean_forecast = forecast.summary_frame()['mean'].to_numpy()\n",
    "        \n",
    "        if return_conf_int:\n",
    "            df = forecast.summary_frame(alpha=alpha)\n",
    "            pi = df[['mean_ci_lower', 'mean_ci_upper']].to_numpy()\n",
    "            return mean_forecast, pi        \n",
    "        else:\n",
    "            return mean_forecast\n",
    "\n",
    "    fittedvalues = property(_get_preds)\n",
    "    resid = property(_get_resids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example fitting and prediction with comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = ExponentialSmoothingWrapper(trend=True, damped_trend=True, \n",
    "                                      seasonal=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = {'shw': model_1}\n",
    "ens = Ensemble(estimators, UnweightedVote())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens.fit(train[REGION])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 5\n",
    "ens_preds = ens.predict(horizon=H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ens_preds, pi = ens.predict(horizon=H, return_conf_int=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2244.63585174, 2251.76403655, 2142.71857983, 2085.26940713,\n",
       "       2072.41902494])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ens_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2142.32799116, 2346.94371233],\n",
       "       [2144.42299751, 2359.10507558],\n",
       "       [2030.56812545, 2254.8690342 ],\n",
       "       [1968.50601141, 2202.03280285],\n",
       "       [1951.21700718, 2193.6210427 ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time Series Cross Validation\n",
    "\n",
    "`time_series_cv` implements rolling forecast origin cross validation for time series.  \n",
    "It does not calculate forecast error, but instead returns the predictions, pred intervals and actuals in an array that can be passed to any forecast error function. (this is for efficiency and allows additional metrics to be calculated if needed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_series_cv(model, train, val, horizons, alpha=0.2, step=1):\n",
    "    '''\n",
    "    Time series cross validation across multiple horizons for a single model.\n",
    "\n",
    "    Incrementally adds additional training data to the model and tests\n",
    "    across a provided list of forecast horizons. Note that function tests a\n",
    "    model only against complete validation sets.  E.g. if horizon = 15 and \n",
    "    len(val) = 12 then no testing is done.  In the case of multiple horizons\n",
    "    e.g. [7, 14, 28] then the function will use the maximum forecast horizon\n",
    "    to calculate the number of iterations i.e if len(val) = 365 and step = 1\n",
    "    then no. iterations = len(val) - max(horizon) = 365 - 28 = 337.\n",
    "    \n",
    "    Parameters:\n",
    "    --------\n",
    "    model - forecasting model\n",
    "\n",
    "    error_func - function to measure forecast error\n",
    "\n",
    "    train - np.array - vector of training data\n",
    "\n",
    "    val - np.array - vector of validation data\n",
    "\n",
    "    horizon - list of ints, forecast horizon e.g. [7, 14, 28] days\n",
    "\n",
    "    step -- step taken in cross validation \n",
    "            e.g. 1 in next cross validation training data includes next point \n",
    "            from the validation set.\n",
    "            e.g. 7 in the next cross validation training data includes next 7 points\n",
    "            (default=1)\n",
    "            \n",
    "    Returns:\n",
    "    -------\n",
    "    np.array - vector of forecast errors from the CVs.\n",
    "    '''\n",
    "    cv_preds = [] #mean forecast\n",
    "    cv_actuals = [] # actuals \n",
    "    cv_pis = [] #prediction intervals\n",
    "    split = 0\n",
    "\n",
    "    print('split => ', end=\"\")\n",
    "    for i in range(0, len(val) - max(horizons) + 1, step):\n",
    "        split += 1\n",
    "        print(f'{split}, ', end=\"\")\n",
    "                \n",
    "        train_cv = np.concatenate([train, val[:i]], axis=0)\n",
    "        model.fit(train_cv)\n",
    "        \n",
    "        #predict the maximum horizon \n",
    "        preds, pis = model.predict(horizon=len(val[i:i+max(horizons)]), \n",
    "                                   return_conf_int=True,\n",
    "                                   alpha=alpha)\n",
    "        \n",
    "        cv_h_preds = []\n",
    "        cv_test = []\n",
    "        cv_h_pis = []\n",
    "        \n",
    "        for h in horizons:\n",
    "            #store the h-step prediction\n",
    "            cv_h_preds.append(preds[:h])\n",
    "            #store the h-step actual value\n",
    "            cv_test.append(val.iloc[i:i+h])    \n",
    "            cv_h_pis.append(pis[:h])\n",
    "                     \n",
    "        cv_preds.append(cv_h_preds)\n",
    "        cv_actuals.append(cv_test)\n",
    "        cv_pis.append(cv_h_pis)\n",
    "        \n",
    "    print('done.\\n')        \n",
    "    return cv_preds, cv_actuals, cv_pis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom functions for calculating CV scores for point predictions and coverage.\n",
    "\n",
    "These functions have been written to work with the output of `time_series_cv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast error in the current split\n",
    "    \n",
    "    Params:\n",
    "    -----\n",
    "    cv_preds, np.array\n",
    "        Split predictions\n",
    "        \n",
    "    \n",
    "    cv_test: np.array\n",
    "        acutal ground truth observations\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "        np.ndarray\n",
    "            cross validation errors for split\n",
    "    '''\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = error_func(cv_test[split], cv_preds[split])\n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv(cv_preds, cv_test, error_func):\n",
    "    '''\n",
    "    Forecast errors by forecast horizon\n",
    "    \n",
    "    Params:\n",
    "    ------\n",
    "    cv_preds: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    cv_test: np.ndarray\n",
    "        Array of arrays.  Each array is of size h representing\n",
    "        the forecast horizon specified.\n",
    "        \n",
    "    error_func: object\n",
    "        function with signature (y_true, y_preds)\n",
    "        \n",
    "    Returns:\n",
    "    -------\n",
    "    np.ndarray\n",
    "        \n",
    "    '''\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error(cv_preds[h], cv_test[h], error_func)\n",
    "        horizon_errors.append(split_errors)\n",
    "\n",
    "    return np.array(horizon_errors)\n",
    "\n",
    "def split_coverage(cv_test, cv_intervals):\n",
    "    n_splits = len(cv_test)\n",
    "    cv_errors = []\n",
    "        \n",
    "    for split in range(n_splits):\n",
    "        val = np.asarray(cv_test[split])\n",
    "        lower = cv_intervals[split].T[0]\n",
    "        upper = cv_intervals[split].T[1]\n",
    "        \n",
    "        coverage = len(np.where((val > lower) & (val < upper))[0])\n",
    "        coverage = coverage / len(val)\n",
    "        \n",
    "        cv_errors.append(coverage)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "    \n",
    "    \n",
    "def prediction_int_coverage_cv(cv_test, cv_intervals):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_intervals = np.array(cv_intervals)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_coverage = []\n",
    "    for h in range(n_horizons):\n",
    "        split_coverages = split_coverage(cv_test[h], cv_intervals[h])\n",
    "        horizon_coverage.append(split_coverages)\n",
    "\n",
    "    return np.array(horizon_coverage)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cv_error_scaled(cv_preds, cv_test, y_train):\n",
    "    n_splits = len(cv_preds)\n",
    "    cv_errors = []\n",
    "    \n",
    "    for split in range(n_splits):\n",
    "        pred_error = mean_absolute_scaled_error(cv_test[split], cv_preds[split], \n",
    "                                                y_train, period=7)\n",
    "        \n",
    "        cv_errors.append(pred_error)\n",
    "        \n",
    "    return np.array(cv_errors)\n",
    "\n",
    "def forecast_errors_cv_scaled(cv_preds, cv_test, y_train):\n",
    "    cv_test = np.array(cv_test)\n",
    "    cv_preds = np.array(cv_preds)\n",
    "    n_horizons = len(cv_test)    \n",
    "    \n",
    "    horizon_errors = []\n",
    "    for h in range(n_horizons):\n",
    "        split_errors = split_cv_error_scaled(cv_preds[h], cv_test[h], y_train)\n",
    "        horizon_errors.append(split_errors)\n",
    "        \n",
    "    return np.array(horizon_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get model and conduct tscv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    '''\n",
    "    Create ensemble model\n",
    "    '''\n",
    "    model_1 = ExponentialSmoothingWrapper(trend=True, damped_trend=True, \n",
    "                                         seasonal=7)\n",
    "    estimators = {'hw': model_1}\n",
    "    return Ensemble(estimators, UnweightedVote())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "model = get_model()\n",
    "\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.2, step=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.870949</td>\n",
       "      <td>3.232631</td>\n",
       "      <td>3.387609</td>\n",
       "      <td>3.498032</td>\n",
       "      <td>3.658897</td>\n",
       "      <td>3.823331</td>\n",
       "      <td>3.935145</td>\n",
       "      <td>4.031783</td>\n",
       "      <td>4.143843</td>\n",
       "      <td>4.211268</td>\n",
       "      <td>4.271285</td>\n",
       "      <td>4.351160</td>\n",
       "      <td>5.124295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.244457</td>\n",
       "      <td>1.436743</td>\n",
       "      <td>1.398462</td>\n",
       "      <td>1.295544</td>\n",
       "      <td>1.314220</td>\n",
       "      <td>1.315240</td>\n",
       "      <td>1.312934</td>\n",
       "      <td>1.280611</td>\n",
       "      <td>1.304054</td>\n",
       "      <td>1.199576</td>\n",
       "      <td>1.108240</td>\n",
       "      <td>1.129762</td>\n",
       "      <td>1.672828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.098028</td>\n",
       "      <td>1.629225</td>\n",
       "      <td>2.038119</td>\n",
       "      <td>2.071345</td>\n",
       "      <td>2.017373</td>\n",
       "      <td>2.420873</td>\n",
       "      <td>2.358999</td>\n",
       "      <td>2.346259</td>\n",
       "      <td>2.408038</td>\n",
       "      <td>2.480246</td>\n",
       "      <td>2.632331</td>\n",
       "      <td>2.889536</td>\n",
       "      <td>3.299821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.034193</td>\n",
       "      <td>2.231086</td>\n",
       "      <td>2.691763</td>\n",
       "      <td>2.848122</td>\n",
       "      <td>2.841323</td>\n",
       "      <td>3.081003</td>\n",
       "      <td>3.077843</td>\n",
       "      <td>3.285958</td>\n",
       "      <td>3.378797</td>\n",
       "      <td>3.509652</td>\n",
       "      <td>3.695005</td>\n",
       "      <td>3.675022</td>\n",
       "      <td>3.736102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.448456</td>\n",
       "      <td>2.721411</td>\n",
       "      <td>2.858200</td>\n",
       "      <td>3.167727</td>\n",
       "      <td>3.362226</td>\n",
       "      <td>3.652577</td>\n",
       "      <td>3.709987</td>\n",
       "      <td>3.693752</td>\n",
       "      <td>3.884546</td>\n",
       "      <td>3.995116</td>\n",
       "      <td>4.079412</td>\n",
       "      <td>4.290042</td>\n",
       "      <td>4.927938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.534764</td>\n",
       "      <td>3.797758</td>\n",
       "      <td>3.582721</td>\n",
       "      <td>3.594094</td>\n",
       "      <td>4.195626</td>\n",
       "      <td>4.276492</td>\n",
       "      <td>4.697929</td>\n",
       "      <td>4.468538</td>\n",
       "      <td>4.426819</td>\n",
       "      <td>4.679833</td>\n",
       "      <td>4.828968</td>\n",
       "      <td>4.740457</td>\n",
       "      <td>6.214774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.752309</td>\n",
       "      <td>8.201948</td>\n",
       "      <td>8.701131</td>\n",
       "      <td>8.447591</td>\n",
       "      <td>8.850626</td>\n",
       "      <td>8.891030</td>\n",
       "      <td>8.859678</td>\n",
       "      <td>8.538516</td>\n",
       "      <td>8.854046</td>\n",
       "      <td>8.505218</td>\n",
       "      <td>8.226571</td>\n",
       "      <td>8.566002</td>\n",
       "      <td>10.585837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    2.870949   3.232631   3.387609   3.498032   3.658897   3.823331   \n",
       "std     1.244457   1.436743   1.398462   1.295544   1.314220   1.315240   \n",
       "min     1.098028   1.629225   2.038119   2.071345   2.017373   2.420873   \n",
       "25%     2.034193   2.231086   2.691763   2.848122   2.841323   3.081003   \n",
       "50%     2.448456   2.721411   2.858200   3.167727   3.362226   3.652577   \n",
       "75%     3.534764   3.797758   3.582721   3.594094   4.195626   4.276492   \n",
       "max     6.752309   8.201948   8.701131   8.447591   8.850626   8.891030   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    3.935145   4.031783   4.143843   4.211268   4.271285   4.351160   \n",
       "std     1.312934   1.280611   1.304054   1.199576   1.108240   1.129762   \n",
       "min     2.358999   2.346259   2.408038   2.480246   2.632331   2.889536   \n",
       "25%     3.077843   3.285958   3.378797   3.509652   3.695005   3.675022   \n",
       "50%     3.709987   3.693752   3.884546   3.995116   4.079412   4.290042   \n",
       "75%     4.697929   4.468538   4.426819   4.679833   4.828968   4.740457   \n",
       "max     8.859678   8.538516   8.854046   8.505218   8.226571   8.566002   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    5.124295  \n",
       "std     1.672828  \n",
       "min     3.299821  \n",
       "25%     3.736102  \n",
       "50%     4.927938  \n",
       "75%     6.214774  \n",
       "max    10.585837  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_preds, cv_test, cv_intervals = results\n",
    "#CV point predictions smape\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, \n",
    "                               symmetric_mean_absolute_percentage_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-hw_smape.csv\n"
     ]
    }
   ],
   "source": [
    "#output sMAPE results to file\n",
    "metric = 'smape'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>77.217641</td>\n",
       "      <td>88.148500</td>\n",
       "      <td>94.071881</td>\n",
       "      <td>98.203561</td>\n",
       "      <td>103.501679</td>\n",
       "      <td>108.349871</td>\n",
       "      <td>111.909771</td>\n",
       "      <td>114.945485</td>\n",
       "      <td>118.453340</td>\n",
       "      <td>121.074300</td>\n",
       "      <td>123.374606</td>\n",
       "      <td>126.188281</td>\n",
       "      <td>144.198494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>36.806688</td>\n",
       "      <td>42.642933</td>\n",
       "      <td>41.965376</td>\n",
       "      <td>39.832151</td>\n",
       "      <td>39.641860</td>\n",
       "      <td>39.092541</td>\n",
       "      <td>38.718744</td>\n",
       "      <td>38.350867</td>\n",
       "      <td>38.399028</td>\n",
       "      <td>35.645921</td>\n",
       "      <td>32.645715</td>\n",
       "      <td>32.063856</td>\n",
       "      <td>36.839152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>35.134065</td>\n",
       "      <td>48.789351</td>\n",
       "      <td>54.457237</td>\n",
       "      <td>58.721873</td>\n",
       "      <td>57.558830</td>\n",
       "      <td>68.618690</td>\n",
       "      <td>66.680558</td>\n",
       "      <td>66.064628</td>\n",
       "      <td>67.897861</td>\n",
       "      <td>69.155446</td>\n",
       "      <td>73.125610</td>\n",
       "      <td>80.318381</td>\n",
       "      <td>103.943216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>55.302277</td>\n",
       "      <td>62.479244</td>\n",
       "      <td>73.175423</td>\n",
       "      <td>76.085373</td>\n",
       "      <td>76.783474</td>\n",
       "      <td>82.575906</td>\n",
       "      <td>83.075776</td>\n",
       "      <td>88.985958</td>\n",
       "      <td>91.386495</td>\n",
       "      <td>96.161811</td>\n",
       "      <td>100.079498</td>\n",
       "      <td>102.447186</td>\n",
       "      <td>114.582753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>65.055825</td>\n",
       "      <td>78.340805</td>\n",
       "      <td>80.751215</td>\n",
       "      <td>83.919310</td>\n",
       "      <td>89.293133</td>\n",
       "      <td>98.463373</td>\n",
       "      <td>99.961035</td>\n",
       "      <td>98.069393</td>\n",
       "      <td>103.865521</td>\n",
       "      <td>111.686042</td>\n",
       "      <td>122.284916</td>\n",
       "      <td>124.630255</td>\n",
       "      <td>140.189152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>87.165244</td>\n",
       "      <td>98.544999</td>\n",
       "      <td>97.261570</td>\n",
       "      <td>98.308341</td>\n",
       "      <td>110.602700</td>\n",
       "      <td>122.174997</td>\n",
       "      <td>142.693911</td>\n",
       "      <td>144.353974</td>\n",
       "      <td>140.136311</td>\n",
       "      <td>140.358974</td>\n",
       "      <td>139.693738</td>\n",
       "      <td>144.184777</td>\n",
       "      <td>166.916891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>213.739761</td>\n",
       "      <td>225.596805</td>\n",
       "      <td>232.153538</td>\n",
       "      <td>222.576604</td>\n",
       "      <td>229.130603</td>\n",
       "      <td>227.959312</td>\n",
       "      <td>226.489084</td>\n",
       "      <td>219.373298</td>\n",
       "      <td>225.908773</td>\n",
       "      <td>219.624089</td>\n",
       "      <td>213.551635</td>\n",
       "      <td>222.858060</td>\n",
       "      <td>265.614654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              7           14          21          28          35          42   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean    77.217641   88.148500   94.071881   98.203561  103.501679  108.349871   \n",
       "std     36.806688   42.642933   41.965376   39.832151   39.641860   39.092541   \n",
       "min     35.134065   48.789351   54.457237   58.721873   57.558830   68.618690   \n",
       "25%     55.302277   62.479244   73.175423   76.085373   76.783474   82.575906   \n",
       "50%     65.055825   78.340805   80.751215   83.919310   89.293133   98.463373   \n",
       "75%     87.165244   98.544999   97.261570   98.308341  110.602700  122.174997   \n",
       "max    213.739761  225.596805  232.153538  222.576604  229.130603  227.959312   \n",
       "\n",
       "              49          56          63          70          77          84   \\\n",
       "count   27.000000   27.000000   27.000000   27.000000   27.000000   27.000000   \n",
       "mean   111.909771  114.945485  118.453340  121.074300  123.374606  126.188281   \n",
       "std     38.718744   38.350867   38.399028   35.645921   32.645715   32.063856   \n",
       "min     66.680558   66.064628   67.897861   69.155446   73.125610   80.318381   \n",
       "25%     83.075776   88.985958   91.386495   96.161811  100.079498  102.447186   \n",
       "50%     99.961035   98.069393  103.865521  111.686042  122.284916  124.630255   \n",
       "75%    142.693911  144.353974  140.136311  140.358974  139.693738  144.184777   \n",
       "max    226.489084  219.373298  225.908773  219.624089  213.551635  222.858060   \n",
       "\n",
       "              365  \n",
       "count   27.000000  \n",
       "mean   144.198494  \n",
       "std     36.839152  \n",
       "min    103.943216  \n",
       "25%    114.582753  \n",
       "50%    140.189152  \n",
       "75%    166.916891  \n",
       "max    265.614654  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CV point predictions rmse\n",
    "cv_errors = forecast_errors_cv(cv_preds, cv_test, root_mean_squared_error)\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-hw_rmse.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'rmse'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.776390</td>\n",
       "      <td>0.876827</td>\n",
       "      <td>0.921432</td>\n",
       "      <td>0.953308</td>\n",
       "      <td>0.998179</td>\n",
       "      <td>1.044021</td>\n",
       "      <td>1.075422</td>\n",
       "      <td>1.102048</td>\n",
       "      <td>1.132846</td>\n",
       "      <td>1.151381</td>\n",
       "      <td>1.168091</td>\n",
       "      <td>1.190157</td>\n",
       "      <td>1.387984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.374427</td>\n",
       "      <td>0.432041</td>\n",
       "      <td>0.421459</td>\n",
       "      <td>0.394370</td>\n",
       "      <td>0.398583</td>\n",
       "      <td>0.398332</td>\n",
       "      <td>0.395551</td>\n",
       "      <td>0.384907</td>\n",
       "      <td>0.388749</td>\n",
       "      <td>0.357200</td>\n",
       "      <td>0.329212</td>\n",
       "      <td>0.331624</td>\n",
       "      <td>0.462209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.315950</td>\n",
       "      <td>0.469174</td>\n",
       "      <td>0.545216</td>\n",
       "      <td>0.557763</td>\n",
       "      <td>0.545605</td>\n",
       "      <td>0.651639</td>\n",
       "      <td>0.635532</td>\n",
       "      <td>0.632770</td>\n",
       "      <td>0.650322</td>\n",
       "      <td>0.670474</td>\n",
       "      <td>0.712974</td>\n",
       "      <td>0.785930</td>\n",
       "      <td>0.899954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.537860</td>\n",
       "      <td>0.596261</td>\n",
       "      <td>0.696459</td>\n",
       "      <td>0.734216</td>\n",
       "      <td>0.759401</td>\n",
       "      <td>0.798927</td>\n",
       "      <td>0.791375</td>\n",
       "      <td>0.856064</td>\n",
       "      <td>0.874999</td>\n",
       "      <td>0.943435</td>\n",
       "      <td>0.979841</td>\n",
       "      <td>0.997156</td>\n",
       "      <td>1.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.651737</td>\n",
       "      <td>0.730453</td>\n",
       "      <td>0.777270</td>\n",
       "      <td>0.834931</td>\n",
       "      <td>0.879109</td>\n",
       "      <td>0.945330</td>\n",
       "      <td>0.991317</td>\n",
       "      <td>1.012393</td>\n",
       "      <td>1.045180</td>\n",
       "      <td>1.085842</td>\n",
       "      <td>1.106382</td>\n",
       "      <td>1.129539</td>\n",
       "      <td>1.327436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.922192</td>\n",
       "      <td>1.030079</td>\n",
       "      <td>0.944162</td>\n",
       "      <td>0.962470</td>\n",
       "      <td>1.135749</td>\n",
       "      <td>1.231902</td>\n",
       "      <td>1.331564</td>\n",
       "      <td>1.285021</td>\n",
       "      <td>1.230079</td>\n",
       "      <td>1.279489</td>\n",
       "      <td>1.322365</td>\n",
       "      <td>1.322210</td>\n",
       "      <td>1.661264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.070509</td>\n",
       "      <td>2.407964</td>\n",
       "      <td>2.525015</td>\n",
       "      <td>2.447888</td>\n",
       "      <td>2.552795</td>\n",
       "      <td>2.560451</td>\n",
       "      <td>2.547150</td>\n",
       "      <td>2.453349</td>\n",
       "      <td>2.537378</td>\n",
       "      <td>2.437239</td>\n",
       "      <td>2.359933</td>\n",
       "      <td>2.452495</td>\n",
       "      <td>2.985912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.776390   0.876827   0.921432   0.953308   0.998179   1.044021   \n",
       "std     0.374427   0.432041   0.421459   0.394370   0.398583   0.398332   \n",
       "min     0.315950   0.469174   0.545216   0.557763   0.545605   0.651639   \n",
       "25%     0.537860   0.596261   0.696459   0.734216   0.759401   0.798927   \n",
       "50%     0.651737   0.730453   0.777270   0.834931   0.879109   0.945330   \n",
       "75%     0.922192   1.030079   0.944162   0.962470   1.135749   1.231902   \n",
       "max     2.070509   2.407964   2.525015   2.447888   2.552795   2.560451   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    1.075422   1.102048   1.132846   1.151381   1.168091   1.190157   \n",
       "std     0.395551   0.384907   0.388749   0.357200   0.329212   0.331624   \n",
       "min     0.635532   0.632770   0.650322   0.670474   0.712974   0.785930   \n",
       "25%     0.791375   0.856064   0.874999   0.943435   0.979841   0.997156   \n",
       "50%     0.991317   1.012393   1.045180   1.085842   1.106382   1.129539   \n",
       "75%     1.331564   1.285021   1.230079   1.279489   1.322365   1.322210   \n",
       "max     2.547150   2.453349   2.537378   2.437239   2.359933   2.452495   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    1.387984  \n",
       "std     0.462209  \n",
       "min     0.899954  \n",
       "25%     1.014067  \n",
       "50%     1.327436  \n",
       "75%     1.661264  \n",
       "max     2.985912  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mase\n",
    "cv_errors = forecast_errors_cv_scaled(cv_preds, cv_test, train[REGION])\n",
    "df = pd.DataFrame(cv_errors)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-hw_mase.csv\n"
     ]
    }
   ],
   "source": [
    "#output rmse\n",
    "metric = 'mase'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.871252</td>\n",
       "      <td>0.884921</td>\n",
       "      <td>0.889947</td>\n",
       "      <td>0.895944</td>\n",
       "      <td>0.903250</td>\n",
       "      <td>0.909392</td>\n",
       "      <td>0.912992</td>\n",
       "      <td>0.917989</td>\n",
       "      <td>0.923040</td>\n",
       "      <td>0.925485</td>\n",
       "      <td>0.973212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.191996</td>\n",
       "      <td>0.183717</td>\n",
       "      <td>0.164329</td>\n",
       "      <td>0.144677</td>\n",
       "      <td>0.144323</td>\n",
       "      <td>0.136958</td>\n",
       "      <td>0.119883</td>\n",
       "      <td>0.104703</td>\n",
       "      <td>0.104028</td>\n",
       "      <td>0.094312</td>\n",
       "      <td>0.085763</td>\n",
       "      <td>0.081253</td>\n",
       "      <td>0.022132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.321429</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.309524</td>\n",
       "      <td>0.387755</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.460317</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.896104</td>\n",
       "      <td>0.904762</td>\n",
       "      <td>0.975342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.938776</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.935065</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.978082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.979592</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.985714</td>\n",
       "      <td>0.980519</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.980822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.991781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.851852   0.857143   0.871252   0.884921   0.889947   0.895944   \n",
       "std     0.191996   0.183717   0.164329   0.144677   0.144323   0.136958   \n",
       "min     0.285714   0.214286   0.238095   0.321429   0.285714   0.309524   \n",
       "25%     0.857143   0.785714   0.833333   0.857143   0.857143   0.857143   \n",
       "50%     0.857143   0.928571   0.952381   0.928571   0.914286   0.928571   \n",
       "75%     1.000000   1.000000   0.952381   0.964286   0.971429   0.976190   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.903250   0.909392   0.912992   0.917989   0.923040   0.925485   \n",
       "std     0.119883   0.104703   0.104028   0.094312   0.085763   0.081253   \n",
       "min     0.387755   0.464286   0.460317   0.514286   0.558442   0.571429   \n",
       "25%     0.857143   0.875000   0.880952   0.885714   0.896104   0.904762   \n",
       "50%     0.938776   0.946429   0.936508   0.928571   0.935065   0.928571   \n",
       "75%     0.979592   0.982143   0.984127   0.985714   0.980519   0.976190   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.973212  \n",
       "std     0.022132  \n",
       "min     0.876712  \n",
       "25%     0.975342  \n",
       "50%     0.978082  \n",
       "75%     0.980822  \n",
       "max     0.991781  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#80% PIs\n",
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-hw_coverage_80.csv\n"
     ]
    }
   ],
   "source": [
    "#output 80% PI coverage\n",
    "metric = 'coverage_80'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rerun for 95% PI coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split => 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, done.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "horizons = [7, 14, 21, 28, 35, 42, 49, 56, 63, 70, 77, 84, 365]\n",
    "model = get_model()\n",
    "\n",
    "results = time_series_cv(model, train[REGION], val[REGION], horizons, \n",
    "                         alpha=0.05, step=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>7</th>\n",
       "      <th>14</th>\n",
       "      <th>21</th>\n",
       "      <th>28</th>\n",
       "      <th>35</th>\n",
       "      <th>42</th>\n",
       "      <th>49</th>\n",
       "      <th>56</th>\n",
       "      <th>63</th>\n",
       "      <th>70</th>\n",
       "      <th>77</th>\n",
       "      <th>84</th>\n",
       "      <th>365</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.964727</td>\n",
       "      <td>0.970899</td>\n",
       "      <td>0.973545</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.978080</td>\n",
       "      <td>0.979497</td>\n",
       "      <td>0.980600</td>\n",
       "      <td>0.982011</td>\n",
       "      <td>0.983165</td>\n",
       "      <td>0.984127</td>\n",
       "      <td>0.994521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.069049</td>\n",
       "      <td>0.105520</td>\n",
       "      <td>0.101095</td>\n",
       "      <td>0.076108</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.054853</td>\n",
       "      <td>0.046992</td>\n",
       "      <td>0.041052</td>\n",
       "      <td>0.036921</td>\n",
       "      <td>0.033053</td>\n",
       "      <td>0.029880</td>\n",
       "      <td>0.027227</td>\n",
       "      <td>0.005635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.869048</td>\n",
       "      <td>0.969863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.982143</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.969388</td>\n",
       "      <td>0.964286</td>\n",
       "      <td>0.968254</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.994521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988095</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             7          14         21         28         35         42   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.973545   0.962963   0.964727   0.970899   0.973545   0.976190   \n",
       "std     0.069049   0.105520   0.101095   0.076108   0.065789   0.054853   \n",
       "min     0.714286   0.571429   0.523810   0.642857   0.685714   0.738095   \n",
       "25%     1.000000   1.000000   1.000000   0.982143   0.971429   0.976190   \n",
       "50%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             49         56         63         70         77         84   \\\n",
       "count  27.000000  27.000000  27.000000  27.000000  27.000000  27.000000   \n",
       "mean    0.978080   0.979497   0.980600   0.982011   0.983165   0.984127   \n",
       "std     0.046992   0.041052   0.036921   0.033053   0.029880   0.027227   \n",
       "min     0.775510   0.803571   0.825397   0.842857   0.857143   0.869048   \n",
       "25%     0.969388   0.964286   0.968254   0.971429   0.974026   0.976190   \n",
       "50%     1.000000   1.000000   1.000000   1.000000   1.000000   0.988095   \n",
       "75%     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "max     1.000000   1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "             365  \n",
       "count  27.000000  \n",
       "mean    0.994521  \n",
       "std     0.005635  \n",
       "min     0.969863  \n",
       "25%     0.994521  \n",
       "50%     0.997260  \n",
       "75%     0.997260  \n",
       "max     0.997260  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95% PIs\n",
    "cv_preds, cv_test, cv_intervals = results\n",
    "cv_coverage = prediction_int_coverage_cv(cv_test, cv_intervals)\n",
    "df = pd.DataFrame(cv_coverage)\n",
    "df.columns = horizons\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../../results/model_selection/stage1/Trust-hw_coverage_95.csv\n"
     ]
    }
   ],
   "source": [
    "#output 95% PI coverage\n",
    "metric = 'coverage_95'\n",
    "print(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')\n",
    "df.to_csv(f'{TOP_LEVEL}/{STAGE}/{REGION}-{METHOD}_{metric}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
