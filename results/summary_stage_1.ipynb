{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1 Model Selection: Summary of Results\n",
    "\n",
    "Model selection was conducted using a method of time series cross-validation called rolling forecast origin. To avoid leakage of future observations, the method incrementally moves the forecast origin forward in time and then makes a prediction. For each new fold we implemented a stride of seven days. We performed a two stage model selection procedure. In the first stage, we used an aggregate regional level time series to screen and identify the most promising candidate models for up to a 365 day forecast (27 folds).\n",
    "\n",
    "This notebook generates the summary result tables and charts for stage 1 of model selection (screening)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cwd[-7:] != \"results\":\n",
    "    mypath = './results/model_selection/temp/'\n",
    "    TABLE_PATH = './paper/tables/'\n",
    "    FIGURE_PATH = './paper/figures/'\n",
    "    APPENDIX_PATH = './paper/appendix/'\n",
    "else:\n",
    "    mypath = './model_selection/temp/'\n",
    "    TABLE_PATH = '../paper/tables/'\n",
    "    FIGURE_PATH = '../paper/figures/'\n",
    "    APPENDIX_PATH = '../paper/appendix/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_files = [f for f in listdir(mypath) if isfile(join(mypath, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean = pd.DataFrame()\n",
    "results_med = pd.DataFrame()\n",
    "results_mean_std = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Estimate Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_measures = ['smape', 'rmse', 'mase', 'coverage_80', 'coverage_95']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in error_measures:\n",
    "    to_read = [filename for filename in result_files if metric in filename]\n",
    "    model_names = [name[:name.index('_')] for name in to_read]\n",
    "    \n",
    "    for filename, model_name in zip(to_read, model_names):\n",
    "        df = pd.read_csv(mypath + filename, index_col=0)\n",
    "\n",
    "        prefix = model_name + '_' + metric\n",
    "        results_mean[prefix + '_mean'] = df.mean()\n",
    "        results_mean[prefix  + '_std'] = df.std()\n",
    "        results_med[prefix + '_med'] = df.median()\n",
    "        results_med[prefix + '_iqr'] = df.quantile(0.75) - df.quantile(0.25)\n",
    "        \n",
    "        results_mean_std[prefix] = results_mean[prefix + '_mean'].map('{:,.2f}'.format) \\\n",
    "            + ' (' + results_mean[prefix  + '_std'].map('{:,.2f}'.format) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_mean.filter(like=\"fbp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formatted results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_forecasts = pd.concat([results_mean_std.filter(like='smape'), \n",
    "                             results_mean_std.filter(like='rmse'),\n",
    "                             results_mean_std.filter(like='mase')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_smape = point_forecasts.filter(like='smape')\n",
    "pf_smape.reindex(sorted(pf_smape.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_rmse = point_forecasts.filter(like='rmse')\n",
    "pf_rmse.reindex(sorted(pf_rmse.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_mase = point_forecasts.filter(like='mase')\n",
    "pf_mase.reindex(sorted(pf_mase.columns), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pf_rmse.columns\n",
    "columns = [s.replace('_rmse', '') for s in columns]\n",
    "pf_rmse.columns = columns\n",
    "pf_rmse.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pf_smape.columns\n",
    "columns = [s.replace('_smape', '') for s in columns]\n",
    "pf_smape.columns = columns\n",
    "pf_smape.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = pf_mase.columns\n",
    "columns = [s.replace('_mase', '') for s in columns]\n",
    "pf_mase.columns = columns\n",
    "pf_mase.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage = results_mean_std.filter(like='80')\n",
    "coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_80 = results_mean_std.filter(like='80')\n",
    "columns = coverage_80.columns\n",
    "columns = [s.replace('_coverage_80', '') for s in columns]\n",
    "coverage_80.columns = columns\n",
    "coverage_80.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coverage_95 = results_mean_std.filter(like='95')\n",
    "columns = coverage_95.columns\n",
    "columns = [s.replace('_coverage_95', '') for s in columns]\n",
    "coverage_95.columns = columns\n",
    "coverage_95.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write these rather large tables to a latex file to use in appendix\n",
    "\n",
    "#Table S1: MASE\n",
    "pf_mase.sort_index(axis=1).to_latex(buf=f'{APPENDIX_PATH}tableS1.tex')\n",
    "\n",
    "#Table S2: 80% Coverage\n",
    "coverage_80.sort_index(axis=1).to_latex(buf=f'{APPENDIX_PATH}tableS2.tex')\n",
    "\n",
    "#Table S3: 95% coverage\n",
    "coverage_95.sort_index(axis=1).to_latex(buf=f'{APPENDIX_PATH}tableS3.tex')\n",
    "\n",
    "#extra rables for sMAPE and RMSE - not used in paper.\n",
    "pf_smape.sort_index(axis=1).to_latex(buf=f'{APPENDIX_PATH}symmetricmape.tex')\n",
    "pf_rmse.sort_index(axis=1).to_latex(buf=f'{APPENDIX_PATH}rootmeansqua.tex')\n",
    "\n",
    "\n",
    "print(f'Appendix summary tables written to {APPENDIX_PATH}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Benchmark (Seasonal Naive)\n",
    "\n",
    "A naive baseline forecasting method was chosen. This was to ensure that the sophisticated methods we test in the study were only considered for the final benchmark if they provided more more accurate point forecasts than the simplest of models. As emergency care demand data are seasonal we opted for the well-known Seasonal Naive method.  This method works by using the most recent observation for the same day and carrying it forward.  For example, if we are forecasting next Tuesday then the observation from the most recent Tuesday is used as the predicted value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_snaive = point_forecasts.filter(like='snaive')\n",
    "pf_snaive.reindex(sorted(pf_snaive.columns), axis=1)\n",
    "columns = pf_snaive.columns\n",
    "columns = [s.replace('_rmse', '') for s in columns]\n",
    "columns = [s.replace('_smape', '') for s in columns]\n",
    "columns = [s.replace('_mase', '') for s in columns]\n",
    "pf_snaive.columns = ['sMAPE', 'RMSE', 'MASE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_snaive[['MASE', 'sMAPE', 'RMSE']].to_latex(buf=f'{TABLE_PATH}table2.tex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf_snaive[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nTable 2: Cross-Validation of Seasonal Naive Point Forecasts')\n",
    "print(pf_snaive[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
